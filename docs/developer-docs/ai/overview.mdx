---
keywords: [intermediate, concept, AI, ai, deAI, deai]
---

import { MarkdownChipRow } from "/src/components/Chip/MarkdownChipRow";

# Decentralized AI overview

<MarkdownChipRow labels={["Intermediate", "Concept", "DeAI" ]} />

Decentralized AI, or DeAI for short, refers to the intersection between AI and blockchain technology.
The term denotes a wide range of applications, starting from peripheral elements such as tokenization or decentralized marketplaces, and going all the way to running AI models fully on-chain as smart contracts.

## What is DeAI?

Similar to term "Web3", people may mean and refer to different things with term "DeAI".
In some cases, the term is diluted and used for platforms and applications are neither decentralized nor trustworthy.

Here is a list of various DeAI applications ordered from the strongest to weakest form of decentralization:

1. **Fully on-chain training and inference**:
This is the truest form of DeAI that brings the security and trustworthiness guarantees of smart contracts to DeAI applications.
Supporting this use case is the long-term vision of ICP that will become possible after integrating GPU-enabled nodes.

2. **Fully on-chain inference on models trained off-chain**:
This assumes that the model was trained off-chained and then uploaded on-chain.
Inference happens fully on-chain and has the same security and trustworthiness guarantees as regular smart contracts.
ICP currently supports this use case for models with millions of parameters.

3. **Storing the model on-chain and running inference on user's device**:
This assumes that the model was trained off-chained and then uploaded on-chain.
Inference happens on user's device after downloading the model.
If the user trusts their own device, then they can trust that the inference ran correctly.
A disadvantage here is that the model needs to be downloaded to user's device with corresponding drawbacks for confidentiality of the model and for user experience due to increased latency.
ICP supports this use case for practically all existing models because a smart contract on ICP can store models up to 400GiB.

4. **Tokenization, marketplaces, orchestration**:
This is about using smart contracts as the tokenization, marketplace, and orchestration layer for AI models and AI hardware.
Since ICP is a general-purpose blockchain, it supports such smart contracts of arbitrary complexity.

5. **Smart contracts calling Web2 AI services**:
Smart contract running on ICP can make HTTP requests to Web2 services including services like OpenAI and Claude.
See [an example](https://github.com/peterpeterparker/juno-openai) of a smart contract calling to OpenAI API.

## Why use DeAI?

DeAI in its truest form can potentially solve [AI's trust problem](https://medium.com/@dfinity/deai-shedding-light-on-ais-black-box-problem-34b29281b743).
Today, users have to blindly trust AI running on centralized servers.
They have no visibility into how their data is used, how AI models produce responses, or whether they work correctly, reliably, and consistently.

Since AI models behave like black boxes to users, building trustworthy AI models is a difficult challenge.
This can be addressed if users are able to verify how a model has been trained and that the inference process uses that very model to generate an output.

Trustworthy DeAI is possible on ICP using canister smart contracts.

## Fully on-chain DeAI

Running AI models on-chain is too compute and memory-intensive for traditional blockchains. ICP was designed to make smart contracts powerful by leveraging the following features:
1. The WebAssembly virtual machine that provides near-native performance.
2. Deterministic time slicing that automatically splits long-running computation over multiple blocks.
3. Powerful node hardware with a standardized specification. Nodes have 32-core CPUs, 512GiB RAM, and 30TB NVMe.

Currently, ICP supports on-chain inference of small models using AI libraries such as [Sonos Tract](https://github.com/sonos/tract) that compile to WebAssembly.
Check out the [image classification example](/docs/current/developer-docs/ai/ai-on-chain) to learn how it works.
The long-term [vision of DeAI on ICP](https://internetcomputer.org/roadmap#Decentralized%20AI-start) is to support on-chain GPU compute to enable both training and inference of larger models.

## Technical working group: DeAI

A technical working group dedicated to discussing decentralized AI and related projects meets bi-weekly on Thursdays at 5pm UTC. You can join via the [community Discord server](https://discord.gg/jnjVVQaE2C).

You can learn more about the group, review the notes from previous meetings, and ask questions on the [DFINITY forum](https://forum.dfinity.org/t/technical-working-group-deai/24621).

## ICP AI projects

Several community projects that showcase how to use AI on ICP are available:

### Rust

- [Sonos Tract](https://github.com/sonos/tract): An open-source AI inference engine that supports ONNX, TensorFlow, PyTorch models and compiles to WebAssembly.
  [The image classification example](https://github.com/dfinity/examples/tree/master/rust/image-classification) explains show to integrate it into a canister to run on ICP.

- [Tract-IC-AI](https://github.com/jeshli/tract-ic-ai): A fork of Sonos Tract that shows an alternative approach of running the inference engine on ICP.

- [Rust-Connect-Py-AI-to-IC](https://github.com/jeshli/rust-connect-py-ai-to-ic): Open-source tool for deploying Python AI models.

- [ic-mnist](https://github.com/smallstepman/ic-mnist): A sort of machine learning 'Hello, world!' running on ICP. [Try it here](https://jsi2g-jyaaa-aaaam-abnia-cai.icp0.io/).

- [ELNA AI](https://github.com/elna-ai): A fully on-chain AI agent platform and marketplace. Supports both on-chain and off-chain LLMs. [Try it here](https://dapp.elna.ai/).

- [Juno + OpenAI](https://github.com/peterpeterparker/juno-openai): An example using Juno and OpenAI to generate images from prompts.

- [UncensoredGreats](https://github.com/UncensoredGreats/core).

- [ArcMind AI](https://github.com/arcmindai/arcmindai): An autonomous agent using Chain of Thoughts for reasoning and actions. Try the [app in-browser](https://arcmindai.app).

- [rust-connect-py-ai-to-ic](https://github.com/jeshli/rust-connect-py-ai-to-ic).

- [ArcMind Vector DB](https://github.com/arcmindai/arcmindvector): A vector database that supports text, image, and audio embedding.

- [Vectune](https://github.com/ClankPan/Vectune): Vectune is a lightweight VectorDB with incremental indexing, based on FreshVamana.

- [ICPanda AI](https://github.com/ldclabs/ic-panda/tree/main/src/ic_panda_ai): An AI chatbot canister based on Huggingfaceâ€™s Candle framework and running Qwen 0.5B model.

### Motoko

- [MotokoLearn](https://github.com/ildefons/motokolearn): A Motoko package that enables on-chain machine learning.

- [In-browser AI chat](https://github.com/patnorris/DecentralizedAIonIC).

- [DeVinci](https://github.com/patnorris/DecentralizedAIonIC): An AI chatbot that uses an open-source LLM. [Check out the canister yourself](https://x6occ-biaaa-aaaai-acqzq-cai.icp0.io/).

### C++

- [icpp-pro Getting Started](https://docs.icpp.world/getting-started.html).

- [icpp_llm](https://github.com/icppWorld/icpp_llm).

- [icpp-llama2 Deployment Tutorial](https://github.com/icppWorld/icpp_llm/blob/main/icpp_llama2/README.md).

- [icgpt](https://github.com/icppWorld/icgpt).

### TypeScript / JavaScript

- [Tensorflow on ICP](https://github.com/carlosarturoceron/decentAI): An Azle example that uses a pre-trained model for making predictions.

- [ICGPT](https://github.com/icppWorld/icgpt): A React frontend that uses a C/C++ backend running an LLM fully on-chain. [Check it out yourself](https://icgpt.icpp.world/).

## AI resources

Machine learning programming:

- [C++ CDK](https://docs.icpp.world/index.html)

- [Rust Burn](https://github.com/Tracel-AI/burn)

- [Tinygrad (Python)](https://github.com/tinygrad/tinygrad)

Distributed AI compute:

- [RingAttention](https://arxiv.org/abs/2310.01889)

- [PetalsML](https://github.com/bigscience-workshop/petals)

- [Stable Horde](https://stablehorde.net/)


Lightweight AI models:

- [TinyLlama](https://github.com/jzhang38/TinyLlama)

- [Qwen 1.8B Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat)

- [SSD-1B](https://huggingface.co/segmind/SSD-1B)

- [Gorilla LLM](https://gorilla.cs.berkeley.edu/)

