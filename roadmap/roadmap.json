[
  {
    "name": "Compute platform",
    "description": "Blockchain Singularity — all computations of the world can run on ICP.",
    "milestones": [
      {
        "name": "End-to-end message processing latency reduction",
        "description": "Reducing the end-to-end client-perceived latency of ingress message processing through a combination of multiple approaches.",
        "milestone_id": "Iridium",
        "eta": "Q3 2024",
        "elements": [
          {
            "title": "QUIC-based transport and P2P layer for consensus",
            "overview": "A QUIC-based implementation of the transport and P2P layer for consensus that cuts down latency and increases throughput.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 2024",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Iridium",
            "notes": "?? Rosti"
          },
          {
            "title": "Synchronous ingress message submission",
            "overview": "Providing a synchronous ingress submission endpoint in addition to the current asynchronous endpoint to reduce perceived end-to-end client-observed latency.",
            "description": "A synchronous ingress submission endpoint considerably reduces the end-to-end client-observed latency for ingress messages as it eliminates the need for polling for the response message. In addition to a latency reduction, it can lead to a bandwidth increase.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Iridium",
            "notes": "?? Rosti"
          },
          {
            "title": "Geolocation-aware ingress routing",
            "overview": "Boundary nodes route ingress messages to one of a set of closeby nodes instead of a random node.",
            "description": "Currently, Boundary Nodes route ingress messages to a random nodes of the target subnet of the message. Selecting the destination node of the message based on its \"distance\" in terms of network latency can help significantly reduce the latency of ingress message submission. The Boundary Node needs to randomly choose from a sufficiently large set of closeby nodes to remain within the trust model of the Internet Computer.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Iridium",
            "notes": "?? Rüdiger"
          },
          {
            "title": "Charging for query calls",
            "overview": "Charge a fair price in cycles for executed query calls. Currently query calls are free and only update calls are charged for.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Iridium",
            "notes": "Ulan: might be opt-in for larger instruction limits for queries (e.g., for AI)"
          }
        ]
      },
      {
        "name": "Improved storage capacity and throughput",
        "description": "Improved storage capacity and ingress throughput for subnets.",
        "milestone_id": "iacp-2",
        "eta": "",
        "elements": [
          {
            "title": "Log-structured merge tree (LSMT) storage layer",
            "overview": "Rewrite the storage layer to rely on log-structured merge trees (LSMTs) instead of XFS reflinking. This will give more fine-grained control over what happens during checkpointing and thus enable further more targeted performance improvements.",
            "description": "The state manager currently relies on XFS reflinks to achieve copy-on-write-like functionality upon writing checkpoints. While this is conceptually nice it delegates some tasks with high optimization potential to the file system. The goal of this feature is to implement an LSMT-based storage layer which will enable optimizations further down the road. We also expect some immediate positive performance impact, such as improved checkpointing times, form this feature.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "iacp-2",
            "notes": "@David: as discussed, this is now a separate item, the other one is in the deployed section; please fill in the details as you see fit"
          },
          {
            "title": "Support 1TB of replicated storage",
            "overview": "Protocol improvements and optimizations of on-disk access and for syncing to reach 1TB of replicated state.",
            "description": "This feature captures the goal to support 1TB of replicated storage per subnets. Work on this feature includes protocol improvements and optimizations related to interacting with the replicated state on disk and when syncing it via state sync. It also includes efforts to make sure that node machines match the hardware requirements in terms of physical disk size etc.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "iacp-2",
            "notes": "Lgtm from Ulan if David is okay with it; David: LGTM as well.",
            "imported": true
          },
          {
            "title": "Increase Stable Memory Limit to 400GiB",
            "overview": "Increasing the stable memory limit of a canister from 96GiB to 400 GiB.",
            "description": "Currently, a canister can access 96GiB of stable memory. This feature will increase this limit to 400GiB for all canisters, allowing canisters to hold more state. The API will remain unchanged. A single message however will not be able to write to more than 8GiB.",
            "forum": "https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/128",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "iacp-2",
            "notes": "?? maybe 500 GB to make it news"
          },
          {
            "title": "Large ingress messages and increased consensus bandwidth",
            "overview": "Support of larger ingress messages than 2 MB and increased ingress bandwidth of subnets.",
            "description": "The current ICP protocol stack constrains ingress messages to 2 MB of size, and constrains the aggregate ingress message size per block to at most 4 MB. The support of large ingress messages intends to lift this limitation and allow for (much) larger ingress messages and therefore to increase the aggregate ingress capacity per block. The technical approach is to only include metadata about the large ingress message, specifically also its hash, in the block to be run through ICP consensus, while the actual large payload is provided directly to the subnet nodes. Via the metadata that goes trough consensus, the nodes can be assured that they all have received the same message. This approach helps to increase the ingress capacity per round and reduce the overhead incurred through the P2P protocol.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "iacp-2",
            "notes": ""
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Increase Stable Memory Limit to 32GiB",
            "overview": "Increasing the stable memory limit of a canister from 8GiB to 32 GiB.",
            "description": "Currently, a canister can access 8GiB of stable memory. This feature will increase that limit to 32GiB for all canisters, allowing canisters to hold more state. The API will remain unchanged. A single message however will not be able to write to more than 8GiB.",
            "forum": "https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/128",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "October 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "HTTPS Outcalls from Canisters",
            "overview": "Enables canisters to make calls to HTTP(S)-based servers. Trustless integration with Web2.",
            "description": "This feature directly integrates Web 3.0 with the Web 2.0 worlds by enabling canister smart contracts on the Internet Computer to make HTTP(S) outcalls to Web 2.0 services outside the blockchain in a completely trustless manner. Using this feature, one can realize a substantial part of the functionalities currently offered by blockchain oracle services, just with better security guarantees and at a lower cost. Possible use cases include directly obtaining market data from HTTP servers for DeFi dapps and decentralized insurance services, sending notifications to end users via traditional communications channels, or implementing, by also using the threshold ECDSA feature, an Ethereum integration entirely in canister space.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-general-integration-proposal/9383",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35639",
            "wiki": "",
            "docs": "https://internetcomputer.org/https-outcalls",
            "eta": "2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Support 450GB replicated storage",
            "overview": "Enhance replicated storage further to 450GB per subnet. Requires protocol improvements and optimizations.",
            "description": "This feature captures the goal to support 450GB of replicated storage on subnets. Work on this feature includes protocol improvements and optimizations related to interacting with the replicated state on disk and when syncing it via state sync. It also includes work to make sure that node machines match the hardware requirements in terms of physical disk size etc.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Wasm-native stable memory",
            "overview": "Letting stable read and write operations directly access replicated memory, similar to how Wasm load and store operations access the the heap.",
            "description": "The goal of introducing Wasm-native stable memory is to improve the performance of stable reads and writes by letting these operations directly access stable memory in the same way Wasm loads and stores access the Wasm heap. <br><br> This will make direct use of stable memory more practical and it will not require canister developers to make any changes to how they use stable memory.",
            "forum": "https://forum.dfinity.org/t/proposal-wasm-native-stable-memory/15966",
            "proposal": "https://dashboard.internetcomputer.org/proposal/88812",
            "wiki": "",
            "docs": "",
            "eta": "2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Increase Stable Memory Limit to 48GiB",
            "overview": "Increasing the stable memory limit of a canister from 32GiB to 48 GiB.",
            "description": "Currently, a canister can access 32GiB of stable memory. This feature will increase that limit to 48GiB for all canisters, allowing canisters to hold more state. The API will remain unchanged. A single message however will not be able to write to more than 8GiB.",
            "forum": "https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/128",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Increase Stable Memory Limit to 96GiB",
            "overview": "Increasing the stable memory limit of a canister from 48GiB to 96GiB.",
            "description": "Currently, a canister can access 48GiB of stable memory. This feature will increase that limit to 96GiB for all canisters, allowing canisters to hold more state. The API will remain unchanged. A single message however will not be able to write to more than 8GiB.",
            "forum": "https://forum.dfinity.org/t/increased-canister-smart-contract-memory/6148/128",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Jan 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/IC-1461"
          },
          {
            "title": "Bazel-based Build System",
            "overview": "Reducing build and testing times through a Bazel-based build system. More aggressive caching. Only perform necessary steps.",
            "description": "As the code base of the Internet Computer grows, build and testing times increase. By switching to a Bazel-based build system, unnecessary build steps are automatically skipped, artifacts can be cached more broadly, and the CI times are significantly reduced. This will affect all community members who verify Internet Computer builds before voting on upgrades.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "July 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Support 750GB replicated storage",
            "overview": "Enhance replicated storage further to 750GB per subnet. Requires protocol improvements and optimizations.",
            "description": "This feature captures the goal to support 750GB of replicated storage on subnets. Work on this feature includes protocol improvements and optimizations related to interacting with the replicated state on disk and when syncing it via state sync. It also includes work to make sure that node machines match the hardware requirements in terms of physical disk size etc.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Locally timing out canister requests",
            "overview": "Timing out canister-to-canister messages during high load.",
            "description": "As opposed to ingress messages, canister-to-canister messages can not timeout at the moment. This feature will introduce the possiblity for the IC to timeout canister-to-canister requests in high-load phases.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-scalability-proposal/9387",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "December 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "David: final.",
            "imported": true
          },
          {
            "title": "High-replication Subnets",
            "overview": "Subnets with higher replication factor than app subnets. Initially ~30 nodes. For highly security-critical dapps such as financial applications.",
            "description": "By increasing the replication factor of a subnet, the security increases as the subnet can tolerate more faults or malicious actors. Highly sensitive dapps, such as DAOs, demand such security levels. With this feature, a developer can choose to deploy a dapp on a high-replication subnet. As there are more replica machines on such subnets, the cycle costs will be higher than on regular application subnets.",
            "forum": "https://forum.dfinity.org/t/introducing-the-first-fiduciary-subnet/17594",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "December 2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Composite queries",
            "overview": "Making queries composable so that a query can call other queries. Supported within a subnet initially.",
            "description": "Canisters have two types of methods: updates and queries. In contrast to updates, queries are not composable. In other words, a query cannot call other queries. <br><br> A composite query is a new type of query that can call other queries. This feature will make it easier for developers to build scalable dapps that shard data across multiple canisters.",
            "forum": "https://forum.dfinity.org/t/proposal-composite-queries/15979",
            "proposal": "https://dashboard.internetcomputer.org/proposal/87599",
            "wiki": "",
            "docs": "",
            "eta": "2023",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Canister Timers",
            "overview": "Timer API to schedule tasks to be run on a canister. Improves on heartbeat API by configuring the frequency.",
            "description": "This feature introduces a new Timer API that will allow canisters to schedule any number of periodic tasks with configurable frequency using a high-level timer library implemented in Motoko and Rust. This is an improvement over the existing Heartbeat API that has no way of configuring the frequency.",
            "forum": "https://forum.dfinity.org/t/heartbeat-improvements-timers-community-consideration/14201/",
            "proposal": "https://dashboard.internetcomputer.org/proposal/88293",
            "wiki": "",
            "docs": "",
            "eta": "Q1 2023",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Network Scalability: State Sync, Certification, and XNet",
            "overview": "Improving network scalability in terms of state sync, certification, and XNet calls",
            "description": "This feature ensures that the Internet Computer meets future scalability requirements in terms of number of subnets and size of their growing canister state. The main focus is on the scalability of the XNet communication protocol and the state sync protocol, including state certification.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-scalability-proposal/9387/3",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35648",
            "wiki": "",
            "docs": "",
            "eta": "February 2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Subnet Splitting MVP",
            "overview": "Subnet splitting allows a subnet and its canisters and state to be split into two subnets with minimal interruption of canisters on the subnet.",
            "description": "The Internet Computer is designed to have unbounded capacity by scaling out to different subnet blockchains.  Each subnet, however, has a bounded capacity: It is limited in how many messages it can process and how much canister memory it can hold.  If a subnet becomes overloaded then the canisters on that subnet may become less responsive or unable to increase their memory usage.  <br><br> Subnet splitting aims to address such issues by providing functionality to split a single subnet into two subnets.  The MVP version can be viewed as a first step towards the vision of full subnet splitting layed out in the forum post linked below.  The goal is to have a fully functional and end to end verifiable process which consists of a series of NNS proposals.  Compared to full subnet splitting the MVP version cuts some corners in terms of automation and minmizing downtime but otherwise follows the same ideas so that the MVP version can be turned into full subnet splitting in future incremental steps.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-subnet-splitting-proposal/9402/4",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35672",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "David: final.",
            "imported": true
          },
          {
            "title": "Deterministic Time Slicing",
            "overview": "A single message execution can span multiple IC rounds. Important for canister upgrades or inherently long-lasting computations.",
            "description": "Deterministic time slicing allows for long(er) running, multi-round computations by suspending the execution at the end of one round and resuming it in the next. <br><br> The feature is currently enabled on all application and verified application subnets. All messages except for queries are automatically sliced and executed in multiple rounds. The instruction limit for such messages has been increased from 5 billion instructions to 20 billion instructions. Further increases will follow after the \"Configurable Wasm Heap Limit\" feature ships.",
            "forum": "https://forum.dfinity.org/t/deterministic-time-slicing/10635",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": true,
            "notes": "",
            "imported": true
          },
          {
            "title": "A subnet can support 100K+ canisters",
            "overview": "Addressing the biggest bottlenecks that prevent 100K+ canisters per subnet. Important for dapps that have a canister per user.",
            "description": "It has been observed that performance degrades (e.g. reduced finalization rate) when a subnet holds many canisters, but in the long term it should be able to support 100K+ canisters on a single subnet. This feature includes work around identifying and addressing the biggest bottlenecks when a subnet is running with many canisters in order to ensure a smooth operation even when many thousands of canisters exist on the same subnet.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Dimitris",
            "imported": true
          },
          {
            "title": "Improved I/O Handling in State Manager",
            "overview": "Improvements of interaction with the disk in the state manager. This includes reducing the number of interactions or taking them out of the state machine loop.",
            "description": "This feature is a collection of improvements to how we interact with the disk in the state manager. By reducing the number of interactions, or taking them out of the state machine loop, we can reduce the instances where the state manager blocks, or otherwise interferes with, execution. The work in this feature is important to make sure that the IC can keep up with the scalability requirements.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-scalability-proposal/9387",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "David: final",
            "imported": true
          },
          {
            "title": "Larger Wasms",
            "overview": "Allow devs to deploy and update Wasm files larger than the current 2 MB limit resulting from the ingress size limit. Achieved by chunking large Wasms and reassembling fragments before installation or update.",
            "description": "The Wasm size for ICP canisters is constrained to the maximum ingress message size of 2 MB because canister installation and upgrade are performed using single ingress messages. 2 MB Wasm files are not sufficient for more complex canisters. The support for larger Wasm files will be implemented by chunking a large Wasm file, uploading the chunks via multiple ingress messages, reconstituting the large Wasm file, and then performing the actual installation or upgrade.",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "status": "deployed",
            "forum": "https://forum.dfinity.org/t/allow-installation-of-large-wasm-modules/17372",
            "eta": "Q1 24",
            "notes": "Ulan: lgtm"
          },
          {
            "title": "Replica-signed queries",
            "overview": "With this feature replicas will start signing query responses. This allows users to verify that intermediaries, e.g., boundary nodes, did not tamper with the response.",
            "description": "Regular queries on the IC are executed by a single replica. This feature will introduce signatures by the replicas, which will prevent dishonest intermediaries (such as boundary nodes) to change the content of a query response. <br><br> Signed query responses are also a precondition for the follow up feature called certified queries which will execute queries against a quorum comprising more than 1/3 of the subnet nodes. If all responses agree on the response payload and contain valid signatures one can conclude that the query response an authentic response relative to the IC's state.",
            "forum": "https://forum.dfinity.org/t/feature-discussion-replica-signed-queries/21793",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "David: certified queries in a dedicated feature captured in the boundary nodes category; made sure this only discusses signed queries. this can be considered final IMO."
          },
          {
            "title": "Reassigning Nodes to Different Subnets",
            "overview": "Allowing nodes to be reassigned from one subnet to another subnet through NNS proposals, without redeploying.",
            "description": "This featured enables nodes to be reassigned to other subnets through simple NNS proposals rather than redeploying nodes from scratch. Nodes now leave old subnet “gracefully”, without counting the departing node in the budget of faulty/malicious nodes in the subnet.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "March 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Observability Solution for Nodes",
            "overview": "Consensus-verified on-chain data of node behaviour. Enables monitoring availability of nodes and penalizing non-performing nodes.",
            "description": "Currently, no publicly verifiable data is available on chain about the behavior of nodes. This data is crucial for monitoring the availability of nodes and penalising nodes that are off line. A solution is explored to have metrics of node performance available on chain.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "?? category; Certified on-chain metrics on node performance accessible through an API. likely https://dfinity.atlassian.net/browse/IC-1591, Trustworthy node metrics for useful work",
            "imported": true
          },
          {
            "title": "Reduction of P2P latency",
            "overview": "Latency improvements of P2P messaging through improved protocol and implementation. Reduces the latency of the consensus protocol and thus improves overall performance.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "Sam: done with P2P improvements; if we ever plan to have substantial efforts there again, we can open a new item; sync, direct access, erasure coding ...; dso: there is no public roadmap item on P2P improvements, this leaving this here now to capture the reduced latency"
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Best-effort messaging",
            "overview": "Extend canister messaging by an additional message type that enables more scalable and responsive dApps.",
            "description": "The current model of guaranteed responses for inter-canister messages based on an extension of the actor model has a few issues that lead to bad user experience. This is the first iteration towards implementing the broader strategy (as described in the motion proposal linked below).",
            "status": "in_progress",
            "forum": "https://forum.dfinity.org/t/scalable-messaging-model/26920",
            "proposal": "https://dashboard.internetcomputer.org/proposal/127668",
            "wiki": "",
            "docs": "",
            "eta": "2024",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": "David: final."
          },
          {
            "title": "Small guaranteed-response messages",
            "overview": "Extend canister messaging by an additional message type with the same guarantees as current messages but puts a tighter upper bound on the message size to allow for more messages that can be in flight at the same time.",
            "description": "The current model of guaranteed responses for inter-canister messages based on an extension of the actor model has a few issues that lead to bad user experience. This is the second iteration towards implementing the broader strategy (as described in the motion proposal linked below).",
            "status": "future",
            "forum": "https://forum.dfinity.org/t/scalable-messaging-model/26920",
            "proposal": "https://dashboard.internetcomputer.org/proposal/127668",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": "Ulan: may not happen, check; David: final."
          },
          {
            "title": "Query call metrics",
            "overview": "Metrics about query calls executed for a canister during a time period. Requirement for a fair charging of cycles for query calls.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "almost done"
          },
          {
            "title": "Increasing instruction limits for query and update calls",
            "overview": "Raising instruction limits of query and update calls. They have limitations of a few billion instructions currently.",
            "description": "Both query and update calls currently have limits in terms of how many instructions can be executed per call. This feature is about increasing those limits by further protocol enhancements. In the current design of the ICP, there are both inherent and practical limits by how much the instructions limits of canister calls can be raised and this feature will need to find a sweet spot within this space to obtain a decent ratio of improvement for the resources spent. Deterministic time slicing (DTS) has already raised the limits of update calls considerably by spanning them over multiple rounds. DTS offers some more potential to increase the number of instructions executed by update calls, but this is limited to what can be computed within a single epoch (the rounds between two checkpoints in a subnet).",
            "eta": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "should be reasonable; community list (Jordan Last): https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/53; ?? how realistic is this"
          },
          {
            "title": "Dapp-level metrics",
            "overview": "Dapp-level metrics allow for obtaining insights into statistics of dapps, e.g., the daily / weekly / monthly active users of a dapp.",
            "description": "Dapp-level metrics are an important aspect of on-chain data analytics. Stakeholder groups such as the dapp developers and potential investors in the dapp or the overall ecosystem have an interest in being able to observe metrics like daily active users (DAUs). The collected metrics can not only be made available within the ICP ecosystem, but also in the systems of major crypto data aggregators, which helps make the data available to a much broader audience beyond the ICP ecosystem. It is still to be determined at which place the metrics are to be collected, e.g., at the protocol level, the Boundary Nodes, through dapps themselves, or a combination thereof.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "Wallet apps (\"Wapps\")",
            "overview": "Wapps are the next evolutionary step of apps: Install your personal apps directly on the blockchain and keep control over your data.",
            "description": "Wapps, which stands for Wallet Apps, are the next step in the evolution of apps. Coming from a world where people install apps on their personal mobile devices from the App Store or Google Play, Wapps are canisters installed on the blockchain from an on-chain store on ICP. This is the next evolution of apps and dapps, where users install their own canister for a dapp and this canister holds all the user's data related to this dapp. Thus, the user remains in full control over their apps and data and can easily delete their data if they wish to not participate in the dapp any more. This makes Wapps a strong concept for app decentralization and privacy.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "Support of 1M canisters per subnet",
            "overview": "Allowing up to 1 million canisters to run on a subnet, up from the current 100K canisters.",
            "description": "The current protocol implementation supports up to 100K canisters per subnet. This is not sufficient in the long term, for example, for dapp architectures that spawn a canister per user and want to grow to millions of users as they would require many of subnets just to host one dapp, while not hitting other subnet limitations such as compute or storage. The goal is to grow the supported number of canisters per subnet to around one million. This requires, among other things, revisiting the current architecture of the backing storage of canisters and how checkpointing the storage is done. A key idea is to differentiate between active and passive canisters, i.e., such that have been active in a given DKG interval and such that have not, respectively. For non-active canisters, processing done during checkpointing, such as writing the canister's backing file to SSD, can be skipped.",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "forum": "https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/9",
            "milestone_id": "",
            "notes": "related forum post (Hamish from OpenChat): https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/9"
          },
          {
            "title": "Support multiple TB of replicated storage",
            "overview": "Enhance replicated storage further to multiple terabytes per subnet. Requires protocol improvements and optimizations.",
            "description": "This feature is the follow up feature to supporting 1TB of replicated storage. The goal is to support multiple terabytes of replicated storage on a subnets. Work on this feature includes protocol improvements and optimizations related to interacting with the replicated state on disk and when syncing it via state sync. It also includes work to make sure that node machines match the hardware requirements in terms of physical disk size etc.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": "Ulan: lgtm if David is okay with it.; David: LGTM as well, I think phrasing the goals in terms of the subnet capacity is good for the roadmap. Together with the many canisters goal this covers most of the scalability work.",
            "imported": true
          },
          {
            "title": "Increase block size and throughput",
            "overview": "Increasing the ICP consensus block size and thus throughput without considerably increasing latency. This improves the performance of subnets and ICP overall.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "?? Manu: is this up in the future or made obsolete by including hashes of ingress messages in blocks; Is this part of large ingress messages or orthogonal"
          },
          {
            "title": "Configurable Wasm memory limit",
            "overview": "Introduce explicit configurable Wasm heap limit. Exceeding the limit alerts the developer instead of bricking the canister when hitting the 4GiB limit.",
            "description": "The Wasm heap of canisters is limited to 4GiB. The limit is fundamental and cannot be increased because of 32-bit memory addresses. If a canister uses all of the available heap space, it will start producing out-of-memory errors and may stop working, which could lead to data loss and bricking of the canister. The developer may not realize this until it is too late to fix the issue. <br><br> This feature aims to introduce an explicit Wasm heap limit that can be configured in the canister settings. The default value for this limit will be a conservative amount, such as 3GiB. If a canister tries to use more memory than the limit, it will receive an out-of-memory error. This will alert the developer to the potential memory issue and allow them to safely upgrade the canister to a version that uses less memory.",
            "forum": "https://forum.dfinity.org/t/proposal-configurable-wasm-heap-limit/17794",
            "proposal": "https://dashboard.internetcomputer.org/proposal/105322",
            "wiki": "",
            "docs": "",
            "eta": "2024",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Dimitris and Ulan",
            "imported": true
          },
          {
            "title": "Canister control audit trail",
            "overview": "Seamless audit trail of management actions on canisters (creation, update, deletion). Allows to trace the sequence of installed canisters versions to source code through a Wasm hash.",
            "description": "The current canister management architecture does not create a seamless audit trail of every change to a canister, such as creation and updates, by its controllers. This implies that there is no seamless audit trail of the code that has run on canisters. This feature addresses this issue by auditing every controller action performed on a canister and storing the associated metadata permanently in the subnet. I.e., all Wasm hashes of the canister's history are logged with timestamps and further metadata in a seamless audit trail. Using this feature and deterministic builds for canisters allows anyone to verify which code has been running at a given time in the canister.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "?? Martin; relates to Messages to specified canister version"
          },
          {
            "title": "Canister Logging MVP",
            "overview": "Allow canisters to log messages during replicated message execution. The logs should be retrievable even when execution traps.",
            "description": "Canister developers have very limited tools at their disposal to debug and fix errors. There's the ability to log some messages via ic0.debug_print, but these are not available to developers in the production IC and it only works if the canister does not trap. This severely limits the usability of this system call. This feature aims to provide some of the missing gaps around canister logging. Initially, only replicated message executions would be supported but canister developers will be able to log errors even when their canister traps and will get access to them via dfx.",
            "status": "in_progress",
            "forum": "https://forum.dfinity.org/t/canister-logging/21300",
            "proposal": "",
            "eta": "2024",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "notes": "final; reviewed by Dimitris; also in community list (Jordan Last)",
            "in_beta": false
          },
          {
            "title": "Improved state certification",
            "overview": "The protocol requires certifying parts of the replicated state every round, which includes hashing the respective parts of the state. The faster this is, the more time can be spent on other things during the round. This feature is about optimizing certification times.",
            "description": "Certifying parts of the replicated state includes building a hash tree containing hashes of all the data that needs to be certified. The goal of this feature is to investigate how (and if) we could profit from caching parts of the trees to improve the certification time.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "David ??",
            "imported": true
          },
          {
            "title": "Messages to specified canister version",
            "overview": "Messages to canisters can be required to be only executed by a specific version of the call target to help guarantee that the intended (e.g., audited) version of the code is running.",
            "description": "This feature allows for ingress or inter-canister messages to specify a specific version of the to-be-called canister. If the canister's actual version does not match the requested version, the call is rejected by the system. The benefit of this is security for the caller as the caller can be assured which version of the canister, and thus which code, is executed by the canister. For canisters that perform critical tasks, e.g., such with financial implications, this functionality is crucial in preventing unintended consequences when a canister has been upgraded and would perform unintended actions.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "only have msg accepted by the specified version \n related to how can one verify the canister, source code etc. \n verifiable canisters relates to this \n should split \n - verify code is correct: formal methods, tools; TLA+ annotations \n - verify correct code runs in the canisters: canister history; deterministic builds \n  - see below; : there was a discussion about exactly this; no high priority; discussed as one way to use canister history to prevent some weird attacks? Ulan: deferring to David"
          },
          {
            "title": "Capabilities",
            "overview": "Capabilities — untamperable self-contained permission tokens — allow users or canisters to perform actions with canisters. Authority can be delegated by delegating a capability to another entity.",
            "description": "Currently, it is hard for a user to delegate authority over actions to smart contracts, e.g., to allow a dapp to perform token transfers on behalf of the user. Capabilities are untamperable tokens that grant an entity access rights that can be delegated to other entities. A capability on the IC will be realized as signed token that grants the recipient authority to perform actions defined in the capability. A first solution can be realized on the application layer, a full solution will integrate into the protocol stack so that capabilities are managed and evaluated by the system when inter-canister calls are executed.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "https://docs.google.com/presentation/d/13INFELqOBrWlaVJvnewwwx8lZIBCr40P6uvmgkt6cDk/edit#slide=id.p \n Like credentials; dapp can do things in your behalf \n ~ authZ \n Björn T: not only users, but also canisters can use capabilities; everyone who uses canister does so because they have capability; can give capability to others; on app layer can realize it as a bearer token; implementation based on PKC; user needs to sign tx and not send only token; canister needs to send message and token; the token is linked to the principal via PKC, need to sign with same key as user. Ulan: I think we need more exploration here before putting it on the public roadmap."
          },
          {
            "title": "Canister groups",
            "overview": "Guarantee collocation of canisters on the same subnet by adding them to canister groups. Groups of canisters are always moved together between subnets.",
            "description": "Communication between canisters on the same subnet is significantly faster than between subnets.  Since inter-canister communication latency is less of a concern, one can scale dapps through multi-canister architectures, as long as the canisters are guaranteed to be collocated.  <br><br> Since upcoming load-balancing mechanisms need to move canisters between subnets, we need to avoid splitting up canisters that are part of the same dapp. Canister groups would allow a dapp developer to explicitly indicate which canisters \"belong\" together and which should always be located on the same subnet.",
            "forum": "https://forum.dfinity.org/t/canister-groups/16015",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "Ulan: do we plan to work on this actually?",
            "imported": true
          },
          {
            "title": "Secure XNet cycles protocol",
            "overview": "Securely sending cycles from a less-trusted subnet, e.g., a UTOPIA subnet, rented subnet, or low-replication subnet, to a regular ICP subnet.",
            "description": "Future extensions of ICP such as private subnets or subnets with a smaller number of nodes may not fulfill the conditions of cycles security and thus require that inter-subnet calls initiated on such subnets to other ICP subnets be secured accordingly. This feature will look into the challenges of securely handling cycles in those types of subnets.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "see original file"
          },
          {
            "title": "Messaging model enhancements",
            "overview": "Enhancing canister messaging by means such as named callbacks and one-shot messages.",
            "description": "The current model of guaranteed responses for inter-canister messages based on an extension of the actor model has a few issues. Some of those issues are addressed with best-effort messaging and small guaranteed-response messages already. The enhancements in this feature address remaining issues with further extensions to the messaging model. Named callbacks are a solution where a call's response is not targeted at a specific memory address of the calling canister, but a named function, to allow upgrades even with pending responses. One-shot messages are canister messages without a response message, thus more aligned with the pure actor model.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": "?? check with Dimitris for name callbacks; could already be solved with best-effort messaging; One-shot messaging: https://dfinity.atlassian.net/browse/IC-829; named callbacks: https://dfinity.atlassian.net/browse/IC-1099"
          },
          {
            "title": "Queries at specified block height",
            "overview": "Execute a query at a specified block height. Prerequisite for use cases like replicating queries on multiple replicas, XNet queries or databases.",
            "description": "Queries today are executed on the state at a block height determined by the replica executing the query. For having queries executed by multiple replicas to have update-like security guarantees, yet being more efficient than updates, it needs to be ensured that the query is executed on the same state height on each of the targeted replicas to receive the same response for honest replicas.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": "another use case: data bases, query same version when sharded data \n esp when done from frontend \n XNet msgs from frontend: need to have consistent state \n - XNet query messages, particularly for FE-driven arch \n need canister versioning also (other feature) \n - relevant together with this one. Ulan: needs discussion; David: also seems to overlap somewhat with the replica-signed (or at least certified) queries. David: I would drop this -- it is not a feature by itself. It may be that we require it for certified queries or for something else (e.g., the feature mentioned in the beginning of this line). But as far as I can tell it has no standalone value."
          },
          {
            "title": "Hyper-scalable inter-subnet message routing",
            "overview": "Hyper-scalable XNet messaging protocol and implementation supporting a practically unlimited number of subnets. The current implementation works well up to a reasonably large number of subnets.",
            "description": "The current inter-subnet message routing protocol uses a point-to-point architecture where a subnet pulls XNet messages from the other subnets. This architecture does not scale to tens of thousands of subnets and needs to be improved to allow for unbounded future scaling. The solution may involve a hierarchic addressing scheme or routing via log n many subnets that are topologically \"in between\" the source and target.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": "David: lgtm. There seems to be a duplicate entry. We should either drop this one or the other one. dso: merged the duplicate into this (minor changes)"
          },
          {
            "title": "Canister migration",
            "overview": "Migrating canisters between subnets. Important for balancing subnet utilization and scaling the IC.",
            "description": "Canister smart contracts on ICP are created on a specific subnet and so far cannot be moved to another subnet. The canister migration feature enables canisters to be moved to other subnets. This requires challenges in the space of canister addressing to be resolved, as well as the state migration to another subnet. Canister migration will enable more flexible and dynamic management of canisters, similar to how VMs or containers can be migrated in Web 2 public cloud or container orchestration environments.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": "David lgtm."
          },
          {
            "title": "Subnet deletion",
            "overview": "Enable subnets to be deleted via NNS proposals.",
            "description": "Currently, subnets on the Internet Computer cannot be deleted, but only changed in terms of their topology. This feature aims to extend the protocol so that it is also possible to subnets via NNS proposals.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "in_beta": false,
            "notes": "David: lgtm."
          },
          {
            "title": "Libraries for large data transfers",
            "overview": "Provide more generalized abstractions to overcome message size limits and make them invisible to developers.",
            "description": "The message size limit of 2MB for a single message on ICP requires dapps to chunk data transfers in order to transfer data sets larger than the limit. Abstracting message size limits through user-space libraries helps avoid that every dapp hitting those limits reimplements this functionality, e.g., chunking, on their own. This would also establish a quasi standard for this problem domain and thus make devs more efficient.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Jordan Last): https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/55"
          },
          {
            "title": "Wasm deduplication",
            "overview": "Deduplicating Wasm code for running many instances of the same Wasm as is done in a-canister-per-user architectures.",
            "description": "Dapps that are architected based on a one-canister-per-dapp model have the same Wasm file stored in a potentially large number of canisters. This unnecessarily consumes large amounts of subnet storage and costs cycles for storage and when updating the Wasm on each of the canisters. This feature is about a deduplication of Wasm files for such usage scenarios so that all canisters essentially can share a single Wasm file. There are some challenges in this area to be overcome and questions to be answered, e.g., does this require a \"master canister\" whose Wasm is managed and acts as template for the other canisters in the dapp, and what happens if this master canister is deleted.",
            "forum": "https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/9",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Hamish Peebles); Ulan: Needs discussion. David: even if we implement deduplication it is not clear how charging would work. Do we really wanna commit to the fact that this wastes cycles in the roadmap? dso: rephrased the storage and cycles wasting"
          },
          {
            "title": "Reduction of call latencies",
            "overview": "Reduce call latencies for the most-used call patterns that negatively affect dapp responsiveness.",
            "description": "The responsiveness of a dapp is affected mainly by the various kinds of call patterns used on ICP: Query calls, update calls, cross-canister calls, http outcalls, etc. Improving the platform for better dapp responsiveness requires an assessment of the different call patterns, their latencies, and how frequently they are used in dapps and what the worst offenders are for different dapp architectures. Based on this, efforts need to taken to improve where optimizations have the largest positive effect on overall dapp responsiveness. It should be noted that the ICP stack has already been quite aggressively optimized in some parts and that latency reduction is expected to hit inherent (physical) limitations, e.g., the message propagation times between the geographically distributed nodes of a subnet, sooner or later in those part of the stack.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Jordan Last): https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/54; David: I wonder whether reduced latencies is the most fruitful direction to look into as we are already close to the theoretical optimum in many cases; maybe throughput is the more realistic thing we might be able tweak (especially cross subnet)."
          },
          {
            "title": "WASI V2 support",
            "overview": "WASI V2 is the upcoming standard for running Wasm programs outside of browser environments.It is expected to become the de-facto standard and be targeted by many libraries and thus should be supported by ICP.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list: https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/41; ?? how realistic is this? Ulan: I am discussing this with Jordan and the author of Wasi polyfill. Hopefully, we can keep this in community. Let's remove this item. Dieter: merged both Wasi-related items and kept them for now as they are also part of the internal org-wide roadmap."
          },
          {
            "title": "HTTPS outcalls V2",
            "overview": "Additional feature for HTTPS outcalls: IPv4 support, single-node outcalls, and fire &amp; forget outcalls. Allows for reduced latencies and reduced cycle costs.",
            "description": "HTTPS outcalls on ICP are a feature that allow smart contracts to interact with Web2 services based on the HTTP protocol. This feature extends the existing HTTPS outcalls with additional functionality that make them better applicable for multiple scenarios. Multiple new functionalities are envisioned to be implemented. <em>IPv4 support:</em> This requires certain ICP nodes to obtain IPv4 addresses and allows to make outcalls to a much broader range of services than only IPv6-enabled services. <em>Single-node outcalls:</em> Only one node in the subnet instead of all perform the outcall. Reduces security for improved performance for non-critical outcalls. <em>Fire &amp; forget outcalls:</em> Outcalls that are sent, while their response is not required and ignored, which is interesting for non-critical calls, e.g., sending push notifications to users.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "maybe put HTTP outcall queries into a separate feature (HTTP outcalls V3): done"
          },
          {
            "title": "HTTPS outcalls V3",
            "overview": "Support HTTPS outcalls also for queries, instead of only update calls.",
            "description": "HTTPS outcalls on ICP are a feature that allow smart contracts to interact with Web2 services based on the HTTP protocol. This feature addresses HTTPS outcalls for queries in addition to update calls. Doing HTTPS outcalls in queries requires a different architecture and has different trust requirements compared to outcalls in update calls. Queries are executed on a single replica only, without consensus being involved. The same would hold for HTTPS outcalls invoked from queries: They are made from a single replica and do not involve consensus. Thus, they are very similar to how HTTPS calls are made by the typical Web2 service. A challenge w.r.t. this feature is the latency increase for queries when supporting outcalls.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "maybe V2 is enough"
          },
          {
            "title": "XNet composite queries",
            "overview": "Extending composite queries to work also across subnets, which gives full power to composite queries and simplifies building large-scale decentralized systems.",
            "description": "Currently, composite queries only work within a subnet when canisters send queries to other canisters. This feature extends composite queries to work for canisters across subnet boundaries. This enables new architecture patterns for dapps where canisters can use queries instead of update calls to obtain data from canisters on different subnets. ",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "also part of community list (Jordan Last); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/56; ?? What else would be required for Jordan's request? Ulan: we are not planning to work on this year."
          },
          {
            "title": "Capacity reservations for system calls",
            "overview": "Allowing canisters to reserve capacity for certain crucial system calls such as chain-key signing or HTTPS outcalls. Reserved capacity is guaranteed to be available to the canister.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "maybe frame more broadly; problem with reservations is getting pricing right"
          },
          {
            "title": "Replica key lifecycle V2 — Proactive security",
            "overview": "Apply key rotation or resharing to a broader range of keys managed by the replica. Improved security against temporarily compromised replicas.",
            "description": "Key rotation or resharing for the private keys of a replica can achieve proactive security for the protocol. Proactive security ensures that in case of a temporary node compromise, security can be restored after the compromise. Currently, only a subset of the keys used by replicas are subject periodic key resharing or key rotation. This feature extends proactive security measures to further keys not yet covered by such.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Resilience against slow nodes",
            "overview": "Punishing ICP nodes that are constantly not performing to specification, i.e., failing too frequently to produce a block successfully when requested or being off-line for considerable time.",
            "description": "The current version of ICP does not actively protect against nodes that are too slow, i.e., cannot keep up with the subnet in terms of processing blocks. Such nodes are constantly behind and thus do not contribute to the subnet. The protection mechanism against slow nodes will detect consistently slow nodes, eject them from the subnet, and replace them with new nodes.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "also would nice to have general punishment for not well behaving nodes"
          },
          {
            "title": "User-paid messages",
            "overview": "Using the regular gas model for specific settings: The caller, instead of the canister, pays for update and query calls.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "was: Charge the caller for update and query calls; exploration: nice, but not doing it right now; ?? update text"
          },
          {
            "title": "Subnet splitting V2",
            "overview": "An enhanced version of subnet splitting where all the heavy lifting is done by the protocol.",
            "description": "The current first version of subnet splitting requires that the orchestration of the splitting by done by people through multiple NNS proposals. In order to further decentralize this, subnet splitting should be controlled by a single NNS proposal and all the orchestration should be done entirely by the protocol. An even more advanced variant could be fully autonomous and automatically split a subnet when it reaches its capacity. This more advanced scenario would bring ICP ceonceptually closer to what public cloud systems are doing in terms of autonomous capacity management.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "V1: https://dfinity.atlassian.net/browse/IC-680"
          },
          {
            "title": "P2P unicast",
            "overview": "Utilizing unicast at the P2P layer to communicate artefacts instead of gossip to decrease bandwidth requirements and improve throughput.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Blob storage",
            "overview": "Storage of large amounts of data in a subnet using a new blob storage architecture with the cost of around 2x the SSD cost. More efficient and cheaper compared to regular storage on ICP.",
            "description": "The storage currently available on ICP is full-featured RAM-like storage that can be arbitrarily read or written by canisters. This generality comes with a cost in terms of replication factor and protocol overhead and a corresponding price tag.<p/><p/> Many use cases can benefit from cheaper read-heavy storage where large objects of data can be written once and then only read or deleted (as a whole). The reduced capabilities of this kind of storage w.r.t. ICP current storage allow it to be realized with substantially less space overhead and thus for a more competitive price. The idea is to use erasure-coded blob storage that has a substantially reduced data replication as compared to today's ICP storage, while maintaining integrity and availability at the cost of increased overhead when reading the data.<p/></p> ICP can greatly benefit from the introduction of this kind of storage by fully utilizing the available physical storage of the nodes and thereby offering a much improved overall platform, potentially offering terabytes of additional storage per subnet in addition to the regular replicated storage. A canister author can choose which storage architecture to use for different parts of their use cases and thus benefit from reduced cycles cost and more storage capacity.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "?? Björn T: erasure coding; when writing, goes through consensus, or would be possible to only upload hash of data and not run it through consensus; when canister reads, must go through consensus; when user reads, need not go through consensus; proably targeted at users reading, not canisters; effort: more than 1 year, more than 2 people; very large; reimplement significant parts of protocol; requires us to solve many problems we have in our protocol; currently rely on full replication of all data; major rewriting of stack; solve resilience etc. again for this"
          },
          {
            "title": "Blob streaming (download)",
            "overview": "High-throughput download of data from a subnet's blob storage. The implementation of this can have the bulk data bypass consensus when being read by a user.",
            "description": "Storage blobs need to be read by canisters and dapps. If erasure coding will be the choice for the storage architecture, reading an erasure-coded blob requires one to read data from a number of subnet replicas greater than the 1/3 subnet threshold and recombining the blocks read to the data. Blob streaming realizes this for large storage objects in a chunked fashion to enable more efficient downloads of large contiguous amounts of blob data, e.g., an on-chain video stream or other object like an image. When a user is reading blob data, which is the main envisioned scenario, the bulk data can bypass consensus.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "see related item"
          },
          {
            "title": "Blob streaming (upload)",
            "overview": "High-throughput upload of data to a subnet's blob storage. An optimized implementation of this can have the bulk data bypass consensus, if uploaded by a user.",
            "description": "Blob data needs to be written by canisters and dapps. If erasure coding will be the choice for the storage architecture, writing data to erasure-coded storage requires one to write data to a number of subnet replicas greater than the 1/3 subnet threshold. Streaming does so for large storage objects in a chunked fashion to enable more efficient contiguous uploads of large amounts of blob data, e.g., an on-chain video stream or other object like an image. When a user is writing blob data, which is the main envisioned scenario, the bulk data can bypass consensus.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "?? should we constrain blob storage only to users reading and writing? should we only consider the efficient read / write scenario bypassing consensus? Björn T; builds on top of above; split into first reading and then writing"
          },
          {
            "title": "Eternal storage",
            "overview": "A storage tier on ICP for which a one-off payment for an unlimited storage duration instead of periodic rent is paid.",
            "description": "The regular replicated memory on ICP requires a rent payment in cycles which is accounted for and charged for per consensus round. This feature intends to introduce a storage tier which rather requires a one-off payment in cycles for an unlimited storage duration.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "Ulan: maybe remove"
          },
          {
            "title": "Structured data storage",
            "overview": "Library for structured data storage in stable memory to enable more powerful and convenient out-of-the-box data storage and querying.",
            "description": "Canisters do not have access to relational databases, but rather rely on storing their data in stable memory. This model requires programmers to take care of implementing their own data structures for efficient storage and querying of data. This feature is about implementing libraries that gives users a convenient higher-level storage abstraction that is well aligned with ICPs storage architecture. The feature complements stable memory data structures.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "?? is this stable structures v2?; Sam: stable structures is basic db structure; to better perform queries, can have structured data storage; maybe library; easily store, query data in stable memory; view your data like in regular DB; DB-level convenience and features on IC"
          },
          {
            "title": "Inter-subnet messaging across trust zones",
            "overview": "Sovereign subnets are typically more centralized than ICP mainnet. Thus, messaging between subnets needs to consider the trust zones the subnets are in to maintain overall security.",
            "description": "With sovereign subnets that are under the control of one entity or a consortium, the canister origin, or, in case of multiple subnets operated by the entity or consortium, even the subnet origin of messages cannot be entirely trusted, i.e., could have been tampered with by the operator of the sovereign subnet(s). This difference in the trust model when compared to regular subnets needs to be taken into consideration for inter-subnet messaging. A potential approach to solving this can be <em>trust zones</em> — sets of subnets where all networks trust each other and can freely communicate with each other. Communication between different trust zones (and mainnet, which can also be considered another trust zone) may be subject to constraints.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Using cycles across trust zones",
            "overview": "Transferring cycles from a sovereign network to ICP mainnet or subnets in different trust zones can, because of their weaker decentralization properties, not rely on directly sending cycles.",
            "description": "Cycles sent from sovereign subnets to other sovereign subnets or ICP mainnet cannot be trusted because sovereign subnets are more centralized and the entity controlling them could compromise the subnet and illegitimately create cycles in unlimited amounts. A potential solution to this is to have the operator of a sovereign subnet deposit cycles into a ledger on the target subnet it wants to communicate with (or on a suitable subnet on mainnet) from which cycles are deducted when calling into the target subnet.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          }
        ]
      }
    ]
  },
  {
    "name": "Chain Fusion",
    "description": "Smart contracts on ICP can orchestrate and augment smart contracts on any relevant chain.",
    "milestones": [
      {
        "name": "ICP’s Chain Fusion technology has full support for EVM chains",
        "description": "This milestone enables chain fusion for the Ethereum network and EVM chains in general.  It will enable canister smart contracts to hold and transaction tokens on these chains and interact with their smart contracts. You will be able to build dapps that combine the best of each chain.",
        "milestone_id": "Dilithium",
        "eta": "2024-05-23",
        "elements": [
          {
            "title": "Chain-key ECDSA signing latency & throughput improvements",
            "overview": "Reducing the latency of threshold ECDSA signing operations by reducing the number of consensus rounds required through protocol improvements.",
            "description": "The ICP's initial implementation of threshold ECDSA, also referred to as chain-key ECDSA, requires seven consensus rounds to compute a signature while consuming an available precomputed value (pre-signature). The protocol can be adapted to require fewer rounds for computing a signature, thus noticably reducing signing latency. Also, the throughput for threshold signing is expected to increase as part of this effort. The optimizations will benefit all applications using chain-key ECDSA.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Dilithium",
            "notes": ""
          },
          {
            "title": "RPC canister for Ethereum & EVM integration",
            "overview": "Communication integration of ICP with EVM blockchains via JSON RPC providers.",
            "description": "This feature is about an RPC-based integration of the Internet Computer with EVM chains, initially targeting the Ethereum network, then also Ethereum L2s and other chains with Wthereum RPC providers. The integration builds a canister smart contract offering a subset of the EVM RPC API on chain, while itself connecting to multiple RPC providers and communicating with them. For security-criticial queries multiple RPC providers can be queried and their responses must match unanimously in order to be considered a valid response to the caller of the canister API. Using multiple RPC providers allows for reducing trust in any single entity, thereby making the approach more decentralized.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Dilithium",
            "notes": ""
          },
          {
            "title": "Chain-key ERC20 (ckERC20) tokens &amp; USDC",
            "overview": "A subset of Ethereum's ERC20 tokens on ICP in the form of \"twin tokens\" called ckERC20 (chain-key ERC20).",
            "description": "This feature brings some of Ethereum's ERC20 tokens over to the IC in the form of chain-key tokens, i.e., twin tokens of the original tokens on the Ethereum network. Particularly the ckERC20 twins of stablecoins, such as USDC and USDT, are of tremendous importance to the IC due to the potential liquidity they can bring over to the ICP ecosystem. The initial implementation is done using HTTPS outcalls to multiple Ethereum JSON RPC providers for reading from and writing to the Ethereum network. Chain-key ECDSA signing (threshold ECDSA) is used for creating the required transactions on the Ethereum network in a completely trustless manner.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-integration-with-the-ethereum-network/9382",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Dilithium",
            "notes": "",
            "imported": true
          }
        ]
      },
      {
        "name": "ICP’s Chain Fusion technology has full support for Bitcoin protocols such as BRC20 and Runes",
        "description": "This milestone enables chain fusion for the Bitcoin network, enabling fully decentralized support of Bitcoin ordinals and runes. This milestone completes the full enablement of Bitcoin with smart contracts through ICP's advanced chain-key cryptography functionalities. You will be able to build dapps that combine the best of Bitcoin and ICP seamlessly.",
        "milestone_id": "Bismuth",
        "eta": "2024-07-25",
        "elements": [
          {
            "title": "Chain-key signing - Multiple keys per subnet",
            "overview": "Enabling the threshold signing implementation to hold multiple secret-shared keys per subnet.",
            "description": "Currently, a single private key can be held by the implementation of chain-key ECDSA (threshold ECDSA) per subnet. This feature generalizes the implementation so that subnets can hold an arbitrary number of secret-shared private keys. This is important for the future implementation of threshold EdDSA &amp; threshold Schnorr signing as this will require further keys to be stored on a subnet.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Bismuth",
            "notes": "?? is this part of the milestone"
          },
          {
            "title": "Threshold Schnorr signatures",
            "overview": "Threshold Schnorr support based on multiparty computation (MPC). Enables trustless integrations with the Bitcoin network using Schnorr-BIP340.",
            "description": "ICP already has a suite of threshold signing protocols for realizing threshold ECDSA signatures. Important use cases, however, require Schnorr-BIP340 threshold signatures. Examples for Schnorr-BIP340 are ordinals and other forms of inscriptions on the Bitcoin network.",
            "status": "in_progress",
            "eta": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Bismuth",
            "notes": "also https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/48"
          },
          {
            "title": "Bitcoin block headers available on chain",
            "overview": "",
            "description": "The current Bitcoin integration holds only the full UTXO state of the Bitcoin network on chain in a canister. This is sufficient for many Bitcoin use cases, but not for the novel use cases of inscriptions, such as those using the BRC20 or Runes protocols. Those require access to certain parts of Bitcoin blocks, specifically the witness area where the inscriptions are stored. Making all block headers available on chain through an API allows anyone to trustlessly verify any Bitcoin block obtained, e.g., through HTTPS outcalls. This allows for indexing Bitcoin ordinals in a completely decentralized and trustless manner fully on chain for the first time.",
            "status": "",
            "eta": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Bismuth",
            "notes": ""
          }
        ]
      },
      {
        "name": "ICP's Chain Fusion technology supports Solana",
        "description": "This milestone enables Chain Fusion for the Solana network. This removes the gap between Solana and ICP and allows for building smart contracts that combine the powers of the two networks. Smart contracts on either network will be able to call smart contracts on the other network.",
        "milestone_id": "Holmium",
        "eta": "Q4 2024",
        "elements": [
          {
            "title": "Threshold EdDSA signatures",
            "overview": "Threshold EdDSA support using cryptographic multiparty computation (MPC). Enables trustless integrations with all chains using EdDSA on the Ed25519 curve, like Solana or Cardano.",
            "description": "ICP already has a suite of threshold signing protocols for realizing threshold ECDSA signatures. Important use cases, however, require EdDSA threshold signatures. An example for EdDSA is the direct integration with blockchains using EdDSA to sign transactions, such as Cardano or Solana. Schnorr and EdDSA are very similar because EdDSA is based on a variant of Schnorr using a specific family of elliptic curves, thus they can share the same high-level protocol.",
            "status": "in_progress",
            "eta": "2024",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Holmium",
            "notes": "also https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/48"
          },
          {
            "title": "Solana RPC canister",
            "overview": "RPC canister connecting to Solana RPC providers to integrate with the Solana network.",
            "description": "Analogous to what has been done for Ethereum and EVM chains in general, this feature defines an RPC canister for Solana that allows for communicating with the Solana network, i.e., reading from and writing to the Solana blockchain. Using multiple RPC providers allows for reducing trust in any single entity, thereby making the approach more decentralized.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Holmium",
            "notes": ""
          },
          {
            "title": "Chain-key SOL (ckSOL) token",
            "overview": "Solana's SOL token on ICP in the form of a \"twin token\" called ckSOL (chain-key SOL)",
            "description": "This feature brings Solana's SOL token over to the IC in the form of a chain-key token, i.e., a twin token of the original SOL token on the Solana network. The ckSOL token is important to the IC due to the potential liquidity it can bring over to the ecosystem. The initial implementation is done using HTTPS outcalls to multiple Solana RPC providers for communication with the Solana network. Chain-key EdDSA signing (using the Ed25519 elliptic curve) is used for trustlessly creating the required transactions for the Solana network.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Holmium",
            "notes": ""
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Direct Bitcoin Integration",
            "overview": "Native integration with the Bitcoin blockchain. Trustless reading from and writing to the Bitcoin network from canister smart contracts.",
            "description": "Direct integration of the Internet Computer with the Bitcoin blockchain enables canister smart contracts to receive, hold and transfer bitcoin. With this feature, neither additional trust assumptions, nor additional parties, such as bridges, are required. Bitcoin integration relies on threshold ECDSA signatures that make it possible for a subnet to sign on behalf of a canister with a secret-shared key.",
            "forum": "https://forum.dfinity.org/t/direct-integration-with-bitcoin/6147",
            "proposal": "https://dashboard.internetcomputer.org/proposal/20586",
            "wiki": "",
            "docs": "https://internetcomputer.org/bitcoin-integration",
            "eta": "2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Threshold ECDSA Signatures (a.k.a. Chain-key ECDSA)",
            "overview": "Threshold ECDSA protocol suite based on multi-party computation (MPC). Enables trustless integrations with ECDSA-based chains.",
            "description": "This feature enables canister smart contracts to have an ECDSA public key and to sign with regard to it. The corresponding secret key is threshold-shared among the nodes of a large subnet. Threshold ECDSA signatures are a prerequisite for the direct integration between the Internet Computer and Bitcoin, Ethereum, and possibly further ECDSA-based blockchains in the future.",
            "forum": "https://forum.dfinity.org/t/threshold-ecdsa-signatures/6152",
            "proposal": "https://dashboard.internetcomputer.org/proposal/21340",
            "wiki": "",
            "docs": "https://internetcomputer.org/docs/current/developer-docs/integrations/t-ecdsa/",
            "eta": "2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "ECDSA key rotation and resharing",
            "overview": "Periodic key rotation and resharing to improve resilience against adaptive attacks against the threshold ECDSA protocol.",
            "description": "To make the threshold ECDSA feature as secure as possible, all ECDSA secret shares are periodically refreshed by resharing the secret key. The encryption keys that are used in this distributed key generation protocol are also regularly updated by the nodes. This makes it harder for an attacker to steal sufficiently many ECDSA key shares, as the attack now has to be performed in a small time window.",
            "forum": "https://forum.dfinity.org/t/threshold-ecdsa-signatures/6152/245",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Chain-key Bitcoin (ckBTC) token",
            "overview": "Twin token of Bitcoin on ICP, realized with the native Bitcoin integration and threshold ECDSA. Fast, low-fee Bitcoin transfers on ICP.",
            "description": "Canister smart contracts on the Internet Computer can control and hold real bitcoin on the Bitcoin network.  However, Bitcoin transactions are slow and expensive.  To address this limitation, we introduce a new token called \"Chain-Key Bitcoin\", or \"ckBTC\", which is an analogue of Bitcoin on the Internet Computer. A canister smart contract that builds on the Bitcoin integration, especially its chain-key ECDSA technology, is able to receive bitcoin and issue ckBTC to the sender. Vice versa, users can use this canister to redeem their ckBTC for real bitcoin. As ckBTC is a token that lives on the Internet Computer, it can be transacted efficiently and with low fees. The ckBTC token is backed 1:1 with real bitcoin that is publicly-verifiably held 100% on chain.",
            "forum": "https://forum.dfinity.org/t/chain-key-bitcoin-ckbtc-bitcoin-wrapped-by-a-smart-contract/17606/",
            "proposal": "https://dashboard.internetcomputer.org/proposal/50135",
            "wiki": "",
            "docs": "",
            "eta": "April 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "X-chain token minter V1 (ERC20-ICP)",
            "overview": "First version of the X-chain token minter bringing the ICP token to Ethereum.",
            "description": "One way of integrating with other blockchains such as Ethereum is to bring tokens from the Internet Computer to other chains. This feature is about bringing the ICP token to the Ethereum network by deploying an MVP of a cross-chain token minter for ERC20ICP, i.e., ICP as an ERC 20 token, on Ethereum. This allows, among other things, for ICP being traded on Ethereum-based DEXs like Uniswap. This effort is expected to bring greater visibility and utility to the ICP token.",
            "status": "deployed",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "2023-09-23",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Chain-key Ether (ckETH) token",
            "overview": "Ethereum's Ether token on ICP in the form of a \"twin token\" called ckETH (chain-key ETH).",
            "description": "This feature brings Ethereum's Ether (ETH) token over to the IC in the form of a chain-key token, i.e., a twin token of the original ETH token on the Ethereum network. The ckETH token is important to the IC due to the potential liquidity it can bring over to the ecosystem. The initial implementation is done using HTTPS outcalls to multiple Ethereum JSON RPC providers for communication with the Ethereum network. Once available in the future, the full Ethereum integration of the Internet Computer will be leveraged for communicating with the Ethereum network in a completely trustless way. Chain-key ECDSA signing (threshold ECDSA) is used for trustlessly creating the required transactions for the Ethereum network.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-integration-with-the-ethereum-network/9382",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "EVM in a canister",
            "overview": "The Bitfinity EVM is implemented as a set of canister smart contracts deployed on ICP. Lower fees, lower latency, and higher throughput than Ethereum. Thanks to chain-key cryptography, the EVM is tightly integrated with the Bitcoin network.",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Oracles with signed responses",
            "overview": "Adding exchange rate oracles that threshold sign their responses. Required for adoption of ICP's trustless oracles in other blockchain ecosystems.",
            "description": "Typical oracle use cases require an oracle to sign its responses. This ensures end-to-end traceability and hence accountability of the data provided by oracles. This feature is about providing oracles that sign their responses on ICP that can be used by other chains. Specifically, the exhange rate canister (XRC) is of interest here as it is a completely trustless oracle that runs fully on chain without relying on any trusted parties. Such signing XRC oracle can be leveraged by dapps on other blockchains, thereby strengthening their trust model and reducing oracle cost.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Chain-Key BRC20 (ckBRC20) tokens",
            "overview": "A generic chain-key variant of BRC20 tokens on ICP to support ordinals.",
            "description": "BRC20 is an experimental fungible token standard on the Bitcoin network. Chain-key BRC20 brings BRC20 tokens to ICP using chain-key technology to create twin tokens in ICP, thereby helping strengthen ICP as a fully-decentralized smart contract platform and DeFi layer for Bitcoin.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Direct Ethereum Integration",
            "overview": "Direct integration of the Internet Computer with the Ethereum blockchain enables canisters to call smart contracts on Ethereum and vice versa in a trustless manner.",
            "description": "Direct integration of the Internet Computer with the Ethereum blockchain will enable smart contracts on the Internet Computer to call smart contracts on Ethereum and vice versa in a trustless manner, without using any (trusted) intermediaries such as bridges.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-integration-with-the-ethereum-network/9382/6",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35635",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "On-chain Bitcoin explorer",
            "overview": "Fully on-chain Bitcoin explorer running on ICP. Adds a missing piece of decentralized infrastructure to the Bitcoin ecosystem.",
            "description": "The world's first blockchain, Bitcoin, has a large ecosystem including tools like block explorers. Besides the blockchain itself, all tools are pure Web2 applications typically hosted in public cloud. This feature implements a fully on-chain Bitcoin block explorer, i.e., brings decentralization and stronger security due to reduced reliance on centralized servers also to the broader landscape of the Bitcoin ecosystem.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "On-chain Ethereum block explorer",
            "overview": "Ethereum block explorer running fully on chain on ICP. Adding a missing piece of decentralized infrastructure to the Ethereum ecosystem.",
            "description": "ICP has the mantra of having 100% on-chain dapp experiences. One such 100% on-chain dapp that is intended to be hosted following this paradigm is an Ethereum block explorer. This would close the gap for Ethereum of block explorers being Web2 applications and would help bring Ethereum closer to a fully on-chain decentralized ecosystem, including its core components that are currently hosted off chain.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Chain-key ECDSA - Throughput improvements",
            "overview": "Improving throughput of chain-key ECDSA via multiple protocol improvements such as batching and parallel processing of crypto operations.",
            "description": "This feature addresses optimizations of the chain-key ECDSA (i.e., threshold ECDSA) implementation of ICP to improve throughputy. Possible approaches used to reach those goals can be to introduce batching techniques to process batches of cryptographic operations, thereby improving performance, or to further parallelize cryptographic operations.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Larger threshold for threshold signing and key backup",
            "overview": "Increasing the threshold of the ECDSA signing and key backup schemes from 1/3 towards up to 1/2 by giving up some availability for stronger security.",
            "description": "This feature is about increasing the threshold for threshold ECDSA signing and corresponding key backup from the current threshold of 1/3 to a threshold of up to 1/2. This would further improve the security of threshold signing on ICP, while making a reasonable tradeoff against the liveness properties of the protocol.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Threshold signing with substantially increased throughput",
            "overview": "Considerably improving threshold signing throughput for threshold Schnorr &amp; EdDSA, compared to the initial threshold ECDSA signing throughput.",
            "description": "Both threshold ECDSA and EdDSA protocols allow for substantial performance improvements through building upon an entirely new protocol architecture. For ECDSA, througput improvements of one to two orders of magnitude of are expected, for EdDSA up to three orders of magnitude.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "X-chain token minter V2 (ERC20-ICRC)",
            "overview": "Enhanced version of the X-chain token minter, generalizing the approach from ICP only to ICRC-1 tokens to be brought to Ethereum.",
            "description": "This feature is about generalizing the approach of the ERC20-ICP X-chain token minter to a broader range of ICRC-1 tokens that can be projected onto the Ethereum network or other EVM networks. Those tokens can, for example, comprise tokens like chain-key tokens (e.g., ckBTC, ckETH) as well as SNS tokens or other important ICRC-1 tokens on ICP which can be made available on Ethereum.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "X-chain token minter V3",
            "overview": "A further enhanced version of the X-chain token minter, bringing ICP and ICRC-1 tokens to other blockchain networks such as Ethereum L2s and Solana.",
            "description": "This feature is the next step in the generalization of the X-chain token minting approach. It broadens the approach to other chains than Ethereum, such as Solana or Ethereum Layer 2 chains.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-1 interface for native BTC, ERC20 and others",
            "overview": "Exposing an ICRC-1 interface to tokens of token standards from other networks, such as BTC or ERC20. This will make X-chain tokens on ICP more easy to use.",
            "description": "",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Ethereum and Bitcoin optimistic logging and settlement",
            "overview": "Settling a fingerprint of a canister's state to high-replication blockchains such as the Bitcoin or Ethereum networks. The initial version is optimistic in that the settled value cannot be publicly verified.",
            "description": "Both the Ethereum and Bitcoin networks have a substantially larger number of nodes amongst which consensus is executed than ICP subnets. For certain high-integrity use cases such as digital assets, regularly settling a state hash of a canister's state to one of of those networks establishes an untamperable record of the canister's state on those networks. This leverages the massive node distribution of those networks to assure the canister smart contract state integrity in addition to what ICP provides. The approach is optimistic in the sense that the settlement does not include a proof of the correct state being settled.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Native USDC integration through CCTP",
            "overview": "Bringing USD Coin (USDC) natively to ICP via integration with Circle's CCTP.",
            "description": "A future step after bringing USDC to ICP as ckUSDC, i.e., as twin token from the Ethereum network, this feature is about a \"native\" integration through Circle's Cross-Chain Transfer Protocol (CCTP). This direct integration avoids one level of indirection of going through the Ethereum network and is the end goal for USDC integration on the Internet Computer.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "",
            "notes": "community list"
          },
          {
            "title": "BTC ordinals indexer and inscriber",
            "overview": "BTC ordinals indexer and inscriber running fully on chain on ICP. Adding a missing decentralized piece of infrastructure to the Bitcoin ecosystem to help them become more decentralized outside of the actual blockchain network.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          }
        ]
      }
    ]
  },
  {
    "name": "Decentralized AI",
    "description": "On-chain AI: Verifiable training of AI models and securely running them on the ICP blockchain. Having training data in canisters makes the data untamperable and enables verifiability of the model trained with this data.",
    "milestones": [
      {
        "name": "Decentralized fully-on-chain AI inference",
        "description": "ICP can run on-chain AI inference in a fully decentralized manner for the first time. This enables integrity-protected AI models and hence an unhackable AI that you can trust.",
        "milestone_id": "Platinum",
        "eta": "2025-03",
        "elements": [
          {
            "title": "Wasm64 execution environment",
            "overview": "The execution environment is lifted to Wasm64 with the benefit of a 64-bit address space and its much larger addressable memory.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Platinum",
            "notes": ""
          },
          {
            "title": "Performance improvements for paging in memory (prefetching)",
            "overview": "Workloads like AI that require to load a large number of continuous memory pages benefit from prefetching pages to reduce the number of page faults and therefore increase performance.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Platinum",
            "notes": ""
          },
          {
            "title": "AI inference engine performance improvements",
            "overview": "The Rust-based open source AI inference engine used on ICP can benefit from further optimizations to improve the performance of software inference.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Platinum",
            "notes": ""
          },
          {
            "title": "SIMD support for Wasm execution",
            "overview": "SIMD (Single Instruction, Multiple Data) support in the Wasm execution engine for better performance of AI inference.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Platinum",
            "notes": ""
          },
          {
            "title": "Deterministic inference",
            "overview": "",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Platinum",
            "notes": ""
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": []
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Canister API for machine learning",
            "overview": "Canisters receive an API to interact with GPU infrastructure on ICP subnets. This API enables canisters to verifiably train and run AI models.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Shared canister memory through memory mapping",
            "overview": "Memory mapping allows canisters to share large common memory areas, e.g., an AI model.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "AI nodes in subnets",
            "overview": "A new ICP subnet type with GPU support is introduced for boosting the machine learning and inference performance of the network.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "ICP subnets receive GPU support for machine learning. Initially, one GPU per GPU-enabled subnet for training with verifiable data and will grow to GPUs on every node machine in GPU-enabled subnets for fully decentralized and trustless training and execution of models."
          },
          {
            "title": "Marketplace for AI models",
            "overview": "ICP receives a marketplace for verifiably on-chain-trained AI models. Downloading a model from this marketplace guarantees its integrity versus models trained off chain.",
            "description": "",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Marketplace for AI training data",
            "overview": "ICP's marketplace for data enables data providers to upload data and customers to license it for on-chain training of AI models. ICP ensures that the data is only used for training models on-chain within ICP and thus ensures data to not leak.",
            "description": "",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Low-replication subnets for LLMs",
            "overview": "Introduction of low-replication subnets for running large language models (LLMs) with appropriate replication factor.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list"
          },
          {
            "title": "Scalable vector DB",
            "overview": "Making a scalable vector database for AI applications available on the ICP.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list; https://forum.dfinity.org/t/technical-working-group-deai/24621/62"
          }
        ]
      }
    ]
  },
  {
    "name": "Privacy",
    "description": "Features related to strengthening data privacy and confidentiality on ICP.",
    "milestones": [
      {
        "name": "Canister smart contracts can store (and compute on) encrypted data.",
        "description": "ICP smart contracts can hold client-encrypted data. On-chain data always remains encrypted, while decryption is done only in the client using a securely derived key. Your dapps benefit from novel privacy-enhanced use cases that are enabled by this.",
        "milestone_id": "Thorium",
        "eta": "Q1 2025",
        "elements": [
          {
            "title": "VETkeys — Threshold Key Derivation",
            "overview": "Implementing threshold key derivation to allow for threshold decryption. Canisters can store end-to-end encrypted user data.",
            "description": "Empower dapps to perform encryption, and threshold decryption, and signing on the IC by allowing canisters to call a threshold key derivation interface. This feature will enable canisters or individual users to encrypt messages under the public key of the subnet, so that they can be decrypted by calling the threshold key derivation interface for the corresponding decryption key that is secret-shared among the replicas. Integrating this feature will enable canisters to store end-to-end encrypted user data (e.g., storage, messaging, social networks) without having to rely on browser storage for user-side secrets, as well as enabling transaction privacy within canisters (e.g., closed-bid auctions, front-running prevention).",
            "forum": "https://forum.dfinity.org/t/threshold-key-derivation-privacy-on-the-ic/16560",
            "proposal": "",
            "wiki": "",
            "docs": "https://internetcomputer.org/docs/current/developer-docs/integrations/vetkeys/technology-overview",
            "eta": "2024",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Thorium",
            "notes": "final; reviewed by Andrea",
            "imported": true
          },
          {
            "title": "User-space libraries for VETkeys",
            "overview": "User-space libraries that make the VETkeys technology easily usable by dapps to improve data confidentiality and privacy.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "2024",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Thorium",
            "notes": "?? we need to think what else we need for VETkeys to make the feature viable",
            "imported": false
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": []
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "SEV Support for Replica Nodes",
            "overview": "Enabling the SEV-SNP trusted computing technology for the Replica VM to protect sensitive data from unauthorized access.",
            "description": "To increase the security of the Replica VMs in terms of integrity and confidentiality, they can be protected via trusted execution as offered by AMD SEV-SNP. This feature will provide the verified Replica VM as a sealed environment protecting sensitive data within the VM from unauthorized access.",
            "forum": "https://forum.dfinity.org/t/amd-sev-virtual-machine-support/6156",
            "proposal": "https://forum.dfinity.org/t/long-term-r-d-tee-enhanced-ic-proposal/9384/4",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/IC-437",
            "imported": true
          },
          {
            "title": "Disaster recovery for SEV-SNP-enabled subnets",
            "overview": "SEV-SNP raises the level of security, but also makes disaster recovery harder. SEV-SNP-enabled subnets need to be made recoverable, e.g., by securely escrowing its secure enclave key material on the NNS.",
            "description": "While SEV-SNP considerably increases the security posture of ICP nodes, and therefore subnets, against attackers targeting their data confidentiality or integrity, it makes disaster recovery considerably harder because all computations are performed entirely in the secure enclave of the CPU and RAM and storage are encrypted with inaccessible keys encapsulated in the OS image of each node. \n In the case of a disaster regarding an SEV-SNP-enabled subnet, there must still be a way to recover the subnet, but without opening new attack vectors on the nodes or subnet. A promising architecture is to escrow the encryption keys used by the secure computing platform on the NNS so that in case of subnet recovery, a new subnet can obtain the keys, pull the encrypted state of the broken subnet and continue operating on this state.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "SEV-SNP-enabled ECDSA subnet",
            "overview": "The threshold ECDSA signing and backup subnets are enabled with SEV-SNP to raise the protection level against data exfiltration attacks by entities with access to the nodes.",
            "description": "ICP nodes currenly run in an operating mode where computations are not secured by a secure encvlave and where data stored in RAM is not encrypted. This provides opportunities for attackers, including dishonest node providers, to penetrate a node and get hold of secret data such as private keys and non-public user data. <p/> SEV-SNP is a security technology integrated in the CPUs used in the ICP nodes that allows for nodes securely attesting to other nodes or community-operated \"validators\" that they run the correct ICP software stack and secures the node by performing all computations in a secure enclave and encrypting all data that goes to RAM or storage. Enabling SEV-SNP in the setting of ICP nodes is challenging due to the complex security and availability requirements of ICP subnets and the involved key management, particularly w.r.t. software upgrades.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "SEV-SNP for app subnets",
            "overview": "Regular app subnets receive SEV-SNP protection to make them harder to tamper with and to enable attestation of running the correct software image.",
            "description": "Besides \"high-profile\" subnets such as threshold ECDSA subnets that host highly valuable key material, also regular app subnets will receive the elevated protection resulting from a deployment of SEV-SNP-secured nodes. Deploying this technology on app subnets makes those subnets considerably more resilient against attacks having the goals of extracting data (violating confidentiality) or tampering with data (violating integrity). This is a crucial step in even better protecting user data that resides on all the nodes of a subnet where the canister containing the data is hosted. This form of protection is also beneficial regarding regulatory compliance with data protection regulations, e.g., the European GDPR.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Fully-homomorphic encryption (FHE)",
            "overview": "Fully-homomorphic encryption (FHE) allows for arbitrary computations on encrypted data and only authorized parties to decrypt the result. Blockchain data privacy.",
            "description": "In traditional compute and current blockchains, all computations happen on plaintext data on the machines. Thus, data is exposed to threads such as unintentional exposure or hacking attacks. FHE allows for computations to be performed on encrypted data, i.e., users encrypt input data at user side and submit ciphertexts on which the processing is performed. The decryption is done again on the user side, thus the node machines never observe plaintext data.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Andrea"
          },
          {
            "title": "Cryptographic multi-party computation (MPC)",
            "overview": "Running MPC on the blockchain nodes allow for privacy-preserving arbitrary computations to be made, with only authorized parties learning the results.",
            "description": "Data privacy on a blockchain is at risk because of plaintext data being stored on the blockchain nodes. Cryptographic multi-party computation enables nodes of a subnet to jointly perform arbitrary computation using interactive cryptographic protocols without needing to see each other's inputs. This can be used to enhance privacy considerably by users secret-sharing their inputs across the nodes and then nodes performing computations on the shares without ever seeing the plaintext data. Cryptographic MPC is one of the main enablers for stronger privacy in distributed systems as it completely obviates the need for the node machines \"seeing\" any plaintext user inputs.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Andrea; Andrea: might merge with FHE because they have strong overlap and we do not know yet whether and what we are going to build here; dso: keep for now in order to have broader roadmap"
          }
        ]
      }
    ]
  },
  {
    "name": "Platform decentralization",
    "description": "Fully decentralize every aspect of development and operation of ICP.",
    "milestones": [
      {
        "name": "New Boundary Node architecture",
        "description": "Boundary nodes get split into NNS-controlled API Boundary Nodes and HTTP Gateways. Anyone will be able to run a Boundary Node, enabling a much more decentralized ICP edge infrastructure with a diverse set of Boundary Node providers.",
        "milestone_id": "Vanadium",
        "eta": "Q2 2024",
        "elements": [
          {
            "title": "Future Boundary-Node Architecture",
            "overview": "Today's monolithic boundary node architecture will be split into API boundary nodes and HTTP gateways, enabling improved modularization and NNS-controlled IC API access.",
            "description": "This feature introduces a revamped architecture for the IC's edge, dividing the existing monolithic boundary node into two distinct entities: API boundary nodes and HTTP gateways. API boundary nodes, under NNS control, handle API call routing, while HTTP gateways, self-managed, facilitate web access by implementing the [HTTP gateway protocol](docs/current/references/http-gateway-protocol-spec). This feature exclusively addresses the architectural shift, while the implementation of separating the current boundary node is tracked separately as 'API Boundary Nodes' and '(Community-owned) HTTP Gateways'.",
            "forum": "https://forum.dfinity.org/t/boundary-node-roadmap/15562",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Vanadium",
            "notes": "architecture is done, move to deployed when both API BN and HTTP Gateway implementations are ready",
            "imported": true
          },
          {
            "title": "API Boundary Nodes",
            "overview": "In the new boundary-node architecture, API boundary nodes are placed under the full control of the NNS and function as the edge of the IC.",
            "description": "This feature decentralizes boundary nodes through the introduction of API boundary nodes. Serving as the IC's edge infrastructure, boundary nodes facilitate communication between clients and the IC. The existing monolithic boundary node undergoes division into an API boundary node and an HTTP gateway to enhance separation of concerns. The NNS will exercise full control over the API boundary node, enabling functions like routing API calls to replicas and implementing rate limiting. API boundary nodes will be  directly accessible from the Internet, facilitating IC native client connectivity. Filtering and deny-listing responsibilities are delegated to the HTTP gateway.",
            "status": "in_progress",
            "forum": "https://forum.dfinity.org/t/boundary-node-roadmap/15562",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Vanadium",
            "notes": "IC-720: https://dfinity.atlassian.net/browse/IC-720"
          },
          {
            "title": "(Community-owned) HTTP Gateways",
            "overview": "As part of the new boundary-node architecture, the HTTP gateway is turned into a standalone service, which is easily deployable by anyone, including end users.",
            "description": "The HTTP gateway enables web access to dapps hosted on the IC by implementing the [HTTP gateway protocol](docs/current/references/http-gateway-protocol-spec). Currently integrated into the monolithic boundary node, it will transition to a standalone component in the future. HTTP gateways, independent of NNS control, offer functionalities such as TLS termination, static asset caching, enforcement of denylists for legal compliance, and translation of HTTP requests to IC API calls. HTTP gateways are easily deployable on servers and end user machines to allow anyone to run them.",
            "forum": "https://forum.dfinity.org/t/boundary-node-roadmap/15562",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "upcoming",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Vanadium",
            "notes": ""
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Gen 2 Replica Node Hardware Specification",
            "overview": "Specification of the Gen 2 hardware for ICP nodes. Vendor independent. Includes new features such as SEV-SNP CPUs.",
            "description": "Components of the first replica node hardware generation are becoming obsolete. By providing a second generation hardware specification, node providers will be able to buy new replica nodes. The new specification is vendor-independent and includes new features such as an SEV-enabled CPU. The specification is described in detail on the [Internet Computer Wiki](https://wiki.internetcomputer.org/wiki/Node_provider_hardware), and has so far been validated for two specific configurations (Asus and Dell). In addition, the first nodes based on this second generation hardware specification have been deployed by independent node providers on the IC network.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "January 2023",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "HostOS upgrades",
            "overview": "NNS-controlled HostOS upgrades enable also the HostOS to be kept up-to-date and security patched via the NNS.",
            "description": "The IC's HostOS, the operating system installed on bare metal machines that hosts the GuestOS is currently not managed by the NNS. This feature makes the HostOS also managed by the NSS and thus upgradeable through proposals. This is a requirement for further features such as IPv4 support in GuestOS or HostOS SSH access.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Feb 2024",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/IC-792"
          },
          {
            "title": "ICOS Boundary Nodes",
            "overview": "Porting the boundary node to the replica's IC OS to simplify operations.",
            "description": "This feature ports the boundary nodes to IC OS, the operating system currently used for replica nodes. Aligning the two images and their build processes, greatly simplifies operations.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-boundary-nodes-proposal/9401",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "eta": "August 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Canister SEO",
            "overview": "Enables dapps on ICP to be index by search engines and previewed on social media. Boundary nodes redirect requests from crawlers and bots to raw in order to avoid loading the service worker.",
            "description": "This features enables dapps on the Internet Computer to be indexed by search engines and previewed on social media (e.g., Twitter cards). Boundary nodes redirect requests from crawlers and bots (e.g., Googlebot) to raw in order to avoid loading the service worker.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "September 2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Canister Deny-listing on Boundary Nodes",
            "overview": "Node providers can deny-list canisters to comply with local regulations and orders. Decentralized content blocking.",
            "description": "This feature gives node providers decentralized means to specify a deny-list for canisters. As node providers are the first to be contacted if questionable content is being stored in a canister smart contract on ICP, adding a deny-listing feature will allow them to make independent decisions about blocking such content, while users can choose which boundary node to use.",
            "forum": "https://forum.dfinity.org/t/path-forward-on-leveraging-boundary-nodes-for-content-filtering/10911",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "October 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Custom Domain Names",
            "overview": "Custom domain names for canisters on ICP. DNS entry of domain redirects to boundary nodes.",
            "description": "This feature enables custom domains on the Internet Computer, so users will not be restricted to using the <canister id>.ic0.app domains. Users can configure the DNS entries of their domain to redirect traffic to the boundary nodes and signal the boundary nodes of the canister to which the traffic should be forwarded. Boundary nodes automatically manage the required certificates for HTTPS.",
            "forum": "https://forum.dfinity.org/t/custom-domains-for-ic0-app-community-consideration/6162",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "https://internetcomputer.org/docs/current/developer-docs/production/custom-domain/",
            "eta": "February 2023",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "WebSocket support in HTTP gateway",
            "overview": "WebSocket-based communication with canister smart contracts through an HTTP gateway. Enables the canister to push messages to the client.",
            "description": "WebSockets provide a bi-directional communication channel between the client (dapp frontend) and the canister (dapp backend). This enables, among others, the canister to push notifications directly to the client and to dynamically update dapp content.",
            "forum": "https://forum.dfinity.org/t/websockets-on-the-ic-psychedelicdao/14817",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "IC-1379: https://dfinity.atlassian.net/browse/IC-1379; maybe done already; Bringing WebSockets to canisters as a bi-directional communication between canisters and dapp frontends.",
            "imported": true
          },
          {
            "title": "Certified Headers",
            "overview": "Flexible certification of canister-defined response headers besides the response body.",
            "description": "Canisters currently only support certification of the response body (e.g., static assets). dapps, however, have varying certification needs (e.g., certifying specific header fields in addition to the body). This feature introduces flexible certification that allows the dapp developer to specify the header fields and assets to be certified.",
            "forum": "https://forum.dfinity.org/t/announcing-response-verification-v2/19135/1",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "March 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Secure access to ICP without service worker",
            "overview": "Relying on local and remote HTTP gateways to securely access ICP dapps from the browser.",
            "description": "To enable secure web access to dapps, the Internet Computer initially used a service worker to handle HTTP requests and verify responses. However, this impacted user and developer experience negatively (e.g., loading time, missing support for SEO). By the end of 2023, the service worker was replaced with two HTTP gateways: the IC HTTP Proxy for local use and icx-proxy for remote access. This setup provides users and developers a familiar web2 experience familiarity while offering the choice of a trusted local gateway.",
            "forum": "https://forum.dfinity.org/t/deprecating-the-service-worker/23401",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "Rüdi"
          },
          {
            "title": "Replica Node Storage Upgrade",
            "overview": "Upgrading the storage of existing replica nodes to 32 TB of NVME SSD.",
            "description": "Thanks to significant improvements in the state manager, state synchronization is no longer a bottleneck when it comes to supporting larger states. Supporting larger states, however, requires more storage on replica nodes. With this upgrade, node providers are supported in extending the storage of their existing replica nodes. The storage upgrade is in full progress and expected to be completed in the 2nd/3th Quarter of 2023.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "?? is this done",
            "imported": true
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Tooling for node provider self onboarding",
            "overview": "Node provider onboarding through improved tooling. Better UX for node provider onboarding than using the command line.",
            "description": "Providing a graphical front-end for the node provider onboarding process to allow for a more user-friendly and less technically complex onboarding experience.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "?? already in progress, PoC done by intern?"
          },
          {
            "title": "Subnet rental",
            "overview": "Anyone can rent subnets created with possibly different decentralization properties than mainnet, have all subnet resources for themselves, and pay the full node provider remuneration including a markup as rent.",
            "description": "Subnet rental follows the idea of having the NNS create subnets that possibly have different decentralization properties than mainnet and allow tenants to rent them. For example, a for-rent subnet could have all its nodes located in one country, e.g., Switzerland. The deviation from ICPs usual decentralization properties may be interesting for a tenant to reap benefits such as regulatory compliance. The tenant of a rental subnet can use its resources alone without sharing with the public and needs to cover the full subnet costs in terms of node provider rewards, including a markup. Due to their different decentralization properties compared with mainnet, for-rent subnets need, much like sovereign subnets, special consideration w.r.t. inter-subnet communication with other subnets or ICP mainnet. See other features in this category for further details.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Non-NNS-approved API Boundary Nodes",
            "overview": "API boundary nodes can operate without requiring NNS approval, allowing anyone to run their own ICP edge infrastructure.",
            "description": "For optimal decentralization of the IC edge infrastructure, another feature focuses on decentralizing API boundary nodes under NNS control. Nonetheless, there exists a use case where API boundary nodes remain outside NNS control, enabling individuals to deploy API boundary nodes. This facilitates community-driven edge infrastructure for dapp users within the IC's subnets.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "Björn T: current view: HTTP gateways not managed anyways; node API would be public; does not know feature; reason for not having BN would be confidential canisters; good reason to not go through BN in such case; or overloaded BNs."
          },
          {
            "title": "HTTP Asset Caching",
            "overview": "Building on response verification v2, HTTP gateways support caching of static assets such as HTML pages, JavaScript code, and images.",
            "description": "This feature enhances user experience by empowering developers to define caching parameters (e.g., time-to-live) for their assets such as HTML pages, JS sources, and images. These caching directives are then made accessible to HTTP gateways, like the icx-proxy on the boundary nodes or the local IC HTTP proxy. By leveraging caching at the edge layer, particularly for static content, a significant portion of traffic can be served from caches instead of querying canisters.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-boundary-nodes-proposal/9401",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "Developers can specify caching policies on assets to be enforced by HTTP gateways.",
            "imported": true
          },
          {
            "title": "Certified queries",
            "overview": "Enable certified queries by having boundary nodes send a query to multiple replicas and aggregating the signed responses. This will lead to better efficience compared to fully-replicated update calls, while providing comparable security properties.",
            "description": "While query calls have very good performance, they only allow to provide the additional security benefits of subnet certifications when dealing with static assets (i.e., via certified variables). Certified queries will allow to secure all query calls (even for dynamic responses) by having the boundary nodes issuing the query to multiple replicas at once, aggregating their signed responses and sending that back to the client.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "upcoming",
            "is_community": false,
            "in_beta": false,
            "notes": "Certifying queries by boundary nodes issuing queries to multiple replicas and responding with signed responses.",
            "imported": true
          },
          {
            "title": "SEV-SNP-protected API Boundary Node",
            "overview": "Security for API boundary nodes is improved using trusted execution (AMD SEV-SNP), enabling anyone to attest that the correct software is running.",
            "description": "This feature aims to enhance security in the API boundary node through trusted execution, leveraging AMD SEV-SNP. This ensures that the software stack running on the API boundary nodes remains untampered and verifiable by anyone (through remote attestation). Consequently, API calls served by these nodes are shielded from access by the Node Providers, as well as boosting confidence in the accuracy and integrity of reported metrics.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-boundary-nodes-proposal/9401",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35671",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "upcoming",
            "is_community": true,
            "in_beta": false,
            "notes": "Securing the Boundary Node VM with the AMD SEV-SNP secure execution environment.",
            "imported": true
          },
          {
            "title": "SEV-SNP-protected HTTP Gateway",
            "overview": "Trusted execution (AMD SEV-SNP) enables trustless HTTP gateways, empowering users to remotely attest that the correct software image is running.",
            "description": "This feature focuses on securing the HTTP gateway through trusted execution, utilizing AMD SEV-SNP. This enables end-users to independently verify the integrity of the gateway's software stack, ensuring it remains untampered. Consequently, users can have confidence that the gateway does not intercept or tamper with the traffic passing through it.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "status": "upcoming",
            "notes": "?? Could we refer to the same motion proposal as for API gateway as this is coming from the Boundary Node? https://dashboard.internetcomputer.org/proposal/35671; then it would be a community feature also; argument may apply to many other Boundary Node features"
          },
          {
            "title": "Certification libraries",
            "overview": "The libraries assist developers in managing certification at the appropriate level of abstraction, addressing the complexity of securely interacting with the IC.",
            "description": "This feature offers a suite of certification libraries tailored for developers, addressing the complexity of securely interacting with the IC end-to-end. Certification is paramount for security, yet often intricate and IC-specific. These libraries provide varying levels of abstraction, empowering developers to certify and verify data with ease.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/response-verification",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "CDN canisters on edge infrastructure",
            "overview": "Read-only canisters run on the ICP edge infrastructure in a non-replicated manner, bringing read-heavy data closer to the edge, analogous to CDNs.",
            "description": "Canister caching involves replicating and deploying heavily accessed canisters on the ICP edge infrastructure. By copying the canister to the edge node, read access scalability is achieved, bringing data closer to users. This approach bears conceptual resemblance to Content Distribution Networks (CDNs). Deploying the ICP's canister execution environment on the edge enables non-replicated query operations from these canisters. Developers must indicate whether caching is suitable for their canisters, considering factors like data confidentiality. This form of caching complements the regular canister response caching, forming an additional aspect of the ICP caching strategy.",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "Björn T: single canister copied; no replica on BN; constrained what canister can do; no X-canister call; content that is read a lot and not written a lot; Dom wants this; large effort; certified canister state pulled to boundary node; if have canister with lots of assets; ~ CDN; because it's a canister, can outsource some computation there; relatively far away; not defined how exactly, e.g., driven by BN or user; canister would need to spec that it is sufficiently public to allow for that; ?? API BN or gateway?"
          },
          {
            "title": "Chain Name System (CNS)",
            "overview": "A decentralized naming system built into the ICP that allows translating user-friendly domains into various records (e.g., A records as used in DNS or wallet addresses), while ensuring verifiability and reliability.",
            "description": "The Chain Name System (CNS) offers a decentralized alternative to web2's Domain Name System (DNS) and expands it for web3 with new record types like wallet addresses. CNS isn't merely a top-level domain (TLD) but a full ecosystem centered around a DAO-managed root. It provides essential tools like resolvers, DNS gateways, and naming canisters (the web3 nameserver), enabling anyone to serve as a TLD provider. CNS empowers users with enhanced control, security, and transparency in domain management.",
            "forum": "https://forum.dfinity.org/t/technical-working-group-naming-system/21236",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/cns",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "IC-1555: https://dfinity.atlassian.net/browse/IC-1555; Rüdi"
          },
          {
            "title": "Improved node management support",
            "overview": "Improving node management by node providers through SSH access or node metrics that help them in troubleshooting node issues.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "?? include SSH access here; goal: NP can troubleshoot and maintain nodes without generating security issues; SSH access and metrics are separate items, what exactly is this about; SSH to guest? SSH access, metrics, troubleshooting"
          },
          {
            "title": "Node Provider Remuneration V3",
            "overview": "Improves the V2 remuneration model by considering things like different multipliers per region, nodes per data center, penalties, or remuneration based on metrics such as cycles burnt.",
            "description": "The remuneration model V2 is being implemented to reward node providers for operating the new Replica HW Specification. This V2 remuneration does not yet take into account penalties for unhealthy nodes or remuneration based on decentralization metrics per country, city, or data center. Remuneration V3 aims to add these features into a fully automated remuneration solution.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "IC-1496: https://dfinity.atlassian.net/browse/IC-1496; Adding penalties for unhealthy nodes to the Remuneration Model V2.",
            "imported": true
          },
          {
            "title": "Strengthened node provider checks and audits",
            "overview": "Strengthening the checks of entities intending to join ICP as node providers. May also include node provider audits.",
            "description": "As participation on the ICP network for node providers has been growing and more and more node providers join the network, it is becoming increasingly important to implement strengthened checks w.r.t. node providers, their identities, and data centers their machines are located in. This is important to prevent sybil attacks and nodes hosted in insufficiently secured locations.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Penalties for non-compliant node providers",
            "overview": "Non-compliant node providers are penalized economically or excluded from future network participation. This creates a cryptoeconomic incentive to encourage honest node provider behaviour.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Autonomous capacity management",
            "overview": "Making capacity management of the ICP network more decentralized and autonomous, driven by community proposals.",
            "description": "Aspects related to capacity management of ICP, such as managing the node pool, creating subnets, splitting subnets, or migrating canister groups to another subnet are currently driven by proposals mostly made by DFINITY teams. This should be made more decentralized so that this responsibility can be tranferred to the community in a first step, requiring the community to be able to monitor relevant metrics accordingly. In a final further step, the protocols itself could handle capacity management in a fully autonomous manner, not requiring proposals.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Community can run system tests",
            "overview": "Enabling the community to run system tests for the ICP codebase, using Kubernetes as container orchestrator.",
            "description": "Currently, the testing facility for running system tests for the ICP codebase is internal to DFINITY and not yet based on Kubernetes. As part of the larger strategy to receive more community contributions to the ICP codebase in the future, the community needs to be enabled to run the system tests for ICP. This requires the system testing framework to migrate to the Kubernetes container orchestrator and to be made available to the public. This feature is a key enabler to future community contributions to the ICP codebase.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Decentralized backup and recovery",
            "overview": "Enabling decentralized backup and recovery of canisters. Recovered canisters are guaranteed not having been tampered with.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "?? Sam: means that everyone should be able to backup subnets; is CUP and all of the state; - remove item? or talk about encrypted backup with key escrowed on NNS"
          },
          {
            "title": "Rewards-driven DRE",
            "overview": "Rewards-driven decentralized reliability (DRE) and capacity management on ICP.",
            "description": "Decentralized reliability, the Web3 analogon of Web2's SRE, is about keeping ICP running reliably. This currently involves DFINITY teams making relevant proposals related to operational aspects of the ICP. This should be further decentralized to involve and incentivize the broader community and increasingly transition DRE to the community. In the long-term future, eligible aspects of DRE should be automated and executed through the protocol without requiring community or DFINITY intervention.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Public access to a subset of node metrics",
            "overview": "Giving node providers access to a subnet of node metrics to help them find out what is failing in case of node issues.",
            "description": "Currently, node providers do not have access to logs and metrics from their nodes. To fully decentralize ICP, node providers themselves need to be able to access certain metrics about nodes in order to find out what is wrong with their nodes. This enables node providers to autonomously fix issues with their nodes without any DFINITY involvement. This is a major prerequisite to a fully decentralized operation of the Internet Computer.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/IC-1479: Allow public access to a subset of node metrics"
          },
          {
            "title": "Off-chain observability stack for Node Providers",
            "overview": "Observability solution for Node Providers to enable them to independently triage node health and take corrective action in case of problems.",
            "description": "The node providers (a) do not have access to the logs and metrics from their node, and (b) do not have access to the alerts we have in place. Therefore, the node providers cannot monitor the health status of their nodes. The objective is to make an observability solution available for node providers that allows them to independently triage the node health and decide whether a node needs to be redeployed, and to independently understand an underlying cause of a node being unhealthy.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Alerting of NP in case of Node Failure",
            "overview": "Alert Node Providers if one of their nodes starts misbehaving or underperforming.",
            "description": "This feature provides a solution for independent node providers to be alerted if their node(s) start misbehaving or underperforming, which would require the node provider's attention. Since node providers do not have direct access to their nodes and node metrics, alerting in case of a node being unhealthy would significantly help the operational activities of node providers.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Decentralized virtual personhood validation",
            "overview": "Scalable, decentralized, virtual proof of personhood to distinguish people from machines.",
            "description": "Being able to distinguish people from machines is important for a blockchain environment where people are not identified when onboarding. There are different ways how this can be achieved. Integrating proof of personhood with ICP will improve decentralization on the Internet Computer, offering greater voting power and rewards to real validated users as opposed to unknown entities. Users can also present the proof of personhood toward dapps, which can provide greater privileges and rewards. <p/><p/> As one option, virtual people parties are a scalable proof of personhood, whereby randomly assigned groups of users validate each other through interaction.",
            "forum": "https://forum.dfinity.org/t/long-term-r-d-people-parties-proof-of-human-proposal/9636",
            "proposal": "https://dashboard.internetcomputer.org/proposal/35668",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Public contributions to IC repository",
            "overview": "Allowing for contributions by the public to the IC source code repository.",
            "description": "Currently the IC repo is open source, but does not allow for contributions by the publicy community. This features aims to make the IC repository available for public contributions. Due to the complexity of the ICP codebase and therefore contributions to it, this is a longer-term goal. A first required step for this is to move the IC repository from GitLab to GitHub.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Gen 3 Replica Node Hardware Specification",
            "overview": "Specification of the Gen 3 hardware for the third generation of ICP nodes.",
            "description": "Following the first and second generations of ICP nodes, there will be a third generation of nodes requiring a new hardware specification, the Gen 3 replica node hardware specification.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          }
        ]
      }
    ]
  },
  {
    "name": "Identity",
    "description": "Blockchain-based self-sovereign identity for Web2 and Web3.",
    "milestones": [
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Device registration via QR code",
            "overview": "Registering another device for an internet identity and linking it to an existing device via scanning a QR code.",
            "description": "By employing QR code technology, users can simply scan the code with their device's camera, instantly initiating the device registration process without the need for manual input of lengthy identifiers or complicated setup procedures. This seamless approach reduces the likelihood of errors and frustration typically associated with traditional methods, enhancing user satisfaction and accelerating the onboarding process. ",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Recovery phrase verification",
            "overview": "Requiring the user to confirm a few random elements of a new recovery phrase to assure they have a copy of the phrase.",
            "description": "Verifying that a user has copied down their recovery phrase is crucial for ensuring the security and accessibility of their account. This step mitigates the risk of data loss or account compromise by confirming that the user has accurately recorded the recovery phrase, which serves as their lifeline for regaining access to their account in the event of password loss or device failure.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Protected recovery phrase",
            "overview": "Requiring knowledge of the previous recovery phrase in order to remove or replace it. Avoids accidental deletion / replacement of the recovery phrase, or through compromised WebAuthn key.",
            "description": "Verifying that a user has copied down their recovery phrase before they lock it mitigates the risk of data loss or account compromise by confirming that the user has accurately recorded the recovery phrase, which serves as their lifeline for regaining access to their account in the event of password loss or device failure.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "II stable memory migration",
            "overview": "Moving identities from heap storage to stable memory data structures. Massively increases available storage for identities and reduces risks of bricking the canister during updates.",
            "description": "By updating the storage for identities, we enabled the improvement of II through new features, including username support.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "II archive canister",
            "overview": "Archive canister for recording any changes to identities managed by II. Provides full traceability regarding IIs.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "II canister subnet migration",
            "overview": "Migration of the II canister from the NNS governance subnet to another high-replication subnet.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "DoS protection based on Captchas",
            "overview": "Captchas are employed to protect the creation of an unlimited amount of IIs by single entities.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Identity creation rate limiting",
            "overview": "Enforing rate limits on the number of new IIs that can be created per time interval to avoid filling up storage of the II canister.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "II metrics",
            "overview": "Providing II-related metrics for the dashboard. Shows the authentication means users have to authenticate to II.",
            "description": "The team now collects the bounce rate and number of daily and monthly authentications using II. This data helps product teams understand how frequently users interact with the product, identify areas for improvement, and make informed decisions to enhance user experience and drive growth, without infringing on user privacy.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "II Temporary Keys",
            "overview": "Social dapps requested that users can onboard to Internet Identity without creating passkeys to reduce friction during onboarding.",
            "description": "The browser generates a private / public key pair that is used to create an identity (and for subsequent authentication). This key pair is then encrypted using both a user-provided password and non-extractable key material local to the browser. This ensures that the encryption on the private key cannot be broken using brute-force attacks even if the user choses a very weak password (which is likely, since it needs to be entered often).",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Streamlined II onboarding",
            "overview": "Streamlined onboarding experience for obtaining a new II. Crucial for bringing more end users into the ICP ecosystem.",
            "description": "The Internet Identity onboarding experience was reduced from 10 steps to 3 steps, and includes tutorials to explain potentially complex concepts.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Alternative origins",
            "overview": "Alternative origins enable domain migration for services users authenticate with. Multiple alternative origins can represent a service and users will have the same principal for those.",
            "description": "Dapps that may be accessible through more than one domain can still have a user have single identity when they authenticate with Internet Identity.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "allowing domain migration for RPs; ?? Do we want to have this on the roadmap?"
          },
          {
            "title": "Login security in stages",
            "overview": "Fast onboarding to Internet Identity and deferred handling of recovery factors such as seed phrases and additional devices.",
            "description": "Users can onboard to Internet Identity without creating recovery phrases and adding devices. However, they are notified every authentication thereafter to improve the security of their Internet Identity through additional recovery and passkeys.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "notes": "quick at first, seed phrase, second device only later (reminder, …); ?? Jan: anything else you expect? the II team does not have additional ideas on how to improve on what is there now"
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Verifiable Credentials",
            "overview": "Verifiable credentials are digital representations of data (qualifications, achievements, or attributes) that are cryptographically secured and portable, enabling efficient and trustworthy sharing of personal data while maintaining privacy and control.",
            "description": "The verifiable credentials protocol facilitates the issuance, presentation, and verification of digital credentials in a decentralized and interoperable manner. Based on W3C's Verifiable Credentials Data Model and the work of the IC's Wallet and Identity Standards Working Group, the protocol outlines a structured approach for parties to issue credentials containing information about individuals, digitally sign them using cryptographic methods to ensure integrity and authenticity, and present these credentials to relying parties when needed. Relying parties can then verify the credentials' authenticity by verifying the digital signatures and checking against decentralized or centralized registries as necessary, enabling trustful interactions while preserving individuals' privacy and control over their data.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/wg-identity-authentication",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Iron",
            "notes": "IC-1522: https://dfinity.atlassian.net/browse/IC-1522; also community list: https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/48"
          },
          {
            "title": "Verifiable Credentials SDK for Relying Parties",
            "overview": "We will be providing tooling, libraries and standards so that relying parties looking to integrate to ICPs VC platform can do so correctly and efficiently.",
            "description": "The next step after the release of ICP's verifiable credential protocol, is to increase its use and make ICP the top platform for self-sovereign identity. We want to facilitiate both web2 and web3 apps to adopt our VC platform.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": true,
            "milestone_id": "Iron",
            "notes": "forum wishlist; SSI SDK: Framework for DID, DIDDoc, verified credentials, selective disclosure etc."
          },
          {
            "title": "Verifiable credentials playground",
            "overview": "A dapp that introduces the concepts of verifiable credentials to prospective identity issuers and relying parties with the aim to facilitate adoption.",
            "description": "The verifiable credentials playground comprises both an issuer and a relying party dapp. Both dapps implement a full end-to-end experience using ICP's verifiable credentials capabilities. The dapps are intended for educational purposes and can act as a template for issuer and relying party dapps building on ICP's VC platform.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": true,
            "milestone_id": "Iron",
            "notes": ""
          },
          {
            "title": "Identity signer standards",
            "overview": "Standards to enable an untrusted relying party (e.g., canister or Web app) to request a signer to sign a transaction for ICP after user approval. Alternative to II's delegation model for high-security use cases or when stable identities are required with different canisters.",
            "description": "Users will be able to use a single wallet address across many different applications, making wallets built on the Internet Computer and relying on Internet Identity for key management to be portable. This way, users can bring their digital assets with them across applications and services while relying on Internet Identity for key management.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/wg-identity-authentication",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Resident passkeys",
            "overview": "Explore the potential of resident passkeys to remove the requirement for users to remember their identity numbers.",
            "description": "We want to double-down on ICP's adoption of passkeys. Passkeys are now used by all the major web2 and web3 players, the aim here is to reduce sign-up and sign-in friction as much as possible by identifying how II can use resident passkeys.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "ICP DID (Decentralised Identifier) method",
            "overview": "Specify a canonical ICP DID method for DID creation, resolution, update, delegation and deletion.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "Verifiable Credentials protocol extension",
            "overview": "The current VC protocol only interacts with the issuer backend when credentials are shared. We want to extend the protocol and allow the VC Issuer frontend to participate in credential sharing. This will unlock significant capabitilies including better UX for existing issuers and improved integration when issuers separate front-end and back-end canisters.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "Verifiable Credentials Billing",
            "overview": "Billing for provisioning of verifiable credentials. Enables a business model for identity providers.",
            "description": "A payment model for verifiable credentials would likely include fees for issuance, verification, and premium services, with options for subscription-based access, transaction fees, bulk discounts, and micropayments, aiming to cover costs related to credential management and validation while ensuring scalability, affordability, and compliance with privacy and security standards.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/wg-identity-authentication",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "",
            "notes": "Either one-off fee or pay-per-use model."
          },
          {
            "title": "Support II authentication to Web2 service",
            "overview": "Secure, privacy-enhancing authentication for Web2 by bringing ICP's II authentication to Web2 services. ",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": "?? likely done already; duplicate of II item"
          },
          {
            "title": "External services authentication to canisters",
            "overview": "Allowing users to authenticate to canisters via Web2-based authentication services. True Web2-Web3-X-SSO.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "",
            "notes": "?? improve name"
          },
          {
            "title": "Usernames instead of Anchors",
            "overview": "Usernames are easier to remember and better reflect what users are used to from Web2 to identify to services.",
            "description": "Transition from a sequential numbering system (anchors) to a username system to enhance the user experience and streamline the onboarding experience by reducing the education required to create an Internet Identity. The shift aims to create a more user-friendly environment, allowing individuals to easily remember and identify with their chosen usernames, as opposed to impersonal and forgettable numerical sequences. This transition is motivated by a strategic move towards a more engaging and user-centric platform that prioritizes personalization and ease-of-use. This will also streamline the onboarding process because users will create their identifier instead of being given one, which is more consistent with conventional authentication systems. ",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "",
            "notes": ""
          },
          {
            "title": "Decentralized KYC",
            "overview": "Decentralized on-chain KYC system that provides a real-world identity backbone to ICP.",
            "description": "Many use cases, such as those related to securities, require users to be subject to KYC and AML verification. This feature builds an on-chain KYC system that provides this functionality to any dapp on ICP, thereby being an important foundation for many types of financial applications.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "?? should this be part of Iron already for an SSI solution: no"
          },
          {
            "title": "Social recovery",
            "overview": "Recovery of an identity in case the device or credentials are lost by recovering the underlying key from the user's social circle who hold key shares.",
            "description": "Social recovery allows users to designate a set of pre-selected contacts who can collectively vouch for their identity in case of emergencies or loss of access. When needed, the user can initiate a recovery process, prompting these trusted contacts to validate their identity. This method enhances security and resilience by distributing the responsibility for identity recovery among trusted peers, reducing reliance on single points of failure such as password recovery emails or security questions, while ensuring user privacy and control over their digital identity.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Configurable II",
            "overview": "Dapps can customize their configuration of II to meet the needs of their users and their product.",
            "description": "Dapps can configure Internet Identity so that only certain authentication methods are exposed to their users. For example, a temporary key may be effective for onboarding users to social dapps, but it is not a secure method for signing financial transactions or managing digital assets. If a user clears their browser history, then the temporary key will be lost, and the user will lose access to the assets associated with it. Therefore, financial dapps may choose not to expose temporary keys as an authentication method for their users.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Transaction Approval",
            "overview": "Allows an untrusted relying party (e.g., canister or Web app) to request from a signer to sign a transaction for ICP after user approval. Alternative to II's delegation model for high-security use cases or when stable identities are required with different canisters.",
            "description": "Users will be able to confirm and authorize a digital currency transaction initiated through the wallet interface. This will require the user to review the transaction details, such as the recipient address, amount, and any associated fees, before digitally signing the transaction by authenticating with their Internet Identity. ",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "https://github.com/dfinity/wg-identity-authentication",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Root domain name independence",
            "overview": "Make internet identities independent of the domain II was executing in when the II has been created. Important to ensure II anchors remain accessible even if II's root domain needs to be switched.",
            "description": "Enables II to switch domains if necessary for branding or accessibility purposes. This initiative makes internet identities independent of the domain II was executing in when the II has been created. Important to ensure II anchors remain accessible even if II's root domain needs to be switched.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Identity management",
            "overview": "Bringing comprehensive identity management features to II: Giving users a 360&deg view on their identities, such as their open sessions, credential sharing history, or pseudonyms used with parties.",
            "description": "Users will be able to manage various identity-related details, including their passkeys, recovery phrases, credentials, and wallet addresses. Users will be able to view and manage their sessions. This holistic perspective allows users to monitor how their identity is being utilized, track access permissions, and detect any potential misuse or unauthorized access. By managing their identity in this manner, users can enhance their privacy, security, and autonomy.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "sessions open, attributes shared, pseudonyms used"
          },
          {
            "title": "Signing with delegated identities",
            "overview": "",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "forum wishlist"
          },
          {
            "title": "ZK-II (Zero-knowledge II)",
            "overview": "Cryptographically privacy-preserving II, based on vetKeys, that unconditionally prevents linkability of identities.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "formerly: Cryptographically privacy-preserving II; ?? Do we want to expose the weakness we currently have? Is this public? Otherwise rephrase"
          }
        ]
      }
    ]
  },
  {
    "name": "Digital assets",
    "description": "Transforming ICP into a digital asset platform, including regulated securities.",
    "milestones": [
      {
        "name": "Next-generation wallets with network custody",
        "description": "ICP's new Oisy and Orbit wallets are released for end users and institutional clients, respectively. Oisy becomes the main wallet on ICP for end users. You can now hand off custody of your assets to advanced, fully on-chain wallets. No centralized entity is required any more as a custodian.",
        "milestone_id": "Silver",
        "eta": "2024-12",
        "elements": [
          {
            "title": "Self-custody Oisy",
            "overview": "Shift Oisy's ownership model to a per-user canister. Under this change, the digital assets for each Oisy user will reside in a user-controlled canister.",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Silver",
            "notes": ""
          },
          {
            "title": "Signer standards in Oisy",
            "overview": "We will upgrade Oisy to support the signer standards. The benefit of signers standards is in fostering a vibrant and diverse ecosystem of signers and relying parties. Users can then safely transact with digital assets using their Oisy wallet and signer standards compatible dApps.",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Silver",
            "notes": "https://dfinity.atlassian.net/browse/IC-1710"
          }
        ]
      },
      {
        "name": "Institutional wallet support on ICP",
        "description": "",
        "milestone_id": "choose-a-metal1",
        "eta": "",
        "elements": [
          {
            "title": "Orbit institutional-grade wallet",
            "overview": "Multisig-like wallet that can enforce complex access control policies on resources. E.g., requiring 2 out of 3 people to authorize ICP transactions above a defined value threshold.",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "choose-a-metal1",
            "notes": ""
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "ICRC-1: Fungible tokens on ICP",
            "overview": "Fungible token standard for the Internet Computer, improving on the ICP token standard. Accounts using principal-subaccount pairs instead of hashed addresses.",
            "description": "The Internet Computer community needs a token standard for fungible tokens besides ICP. ICRC-1 is the first standard in the ICRC (Internet Computer Request for Comments) series of standards. ICRC-1 defines a fungible token standard that is intended for use for any token besides ICP. It features a simplified model of for addresses, namely through principal-subaccount pairs instead of using the hash of the principal and subaccount as address as done for the ICP token. ICRC-1 provides only an active transfer flow, delegations similar to Ethereum's approve and transfer from are added with ICRC-2.",
            "status": "deployed",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-2: Approve and transfer_from for ICRC-1 tokens",
            "overview": "Extending ICRC-1 with ERC-20-stlye approve / transfer_from functionality, but enhanced for the IC.",
            "description": "ICRC-1 is the fungible token standard of the Internet Computer Protocol for fungible tokens besides ICP. ICRC-2 adds the functionality of approve and transfer_from that is well known from Ethereum's ERC-20 standard to ICRC-1. This allows a token holder to approve another party, the spender, to transfer a given amount of the token holder's tokens. The spender can make use of the approval as long as it is valid to transfer tokens on behalf of the token holder. ICRC-2 complements ICRC-1 with much simplified transfer flows for many relevant use cases.",
            "status": "deployed",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Oisy",
            "overview": "Network custodial wallet for EVM blockchains. Naming derived from Open-Internet-Services-like (OISy).",
            "description": "",
            "status": "deployed",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-3: transaction log for ICRC ledgers standard",
            "overview": "Standard for the transaction log format for ICRC ledgers. Prerequisite for unified integration of ICRC tokens with centralized exchanges.",
            "description": "Ledgers on ICP need to implement their tx log in user space as ICP blocks are neither exposed to the public nor retained indefinitely. ICRC-3 defines the format of the block log for ICRC-compliant fungible token and NFT ledgers.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "March 2024",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "On-ramp for ICP and other tokens",
            "overview": "On-ramping for ICP and further tokens to simplify the onboarding experience",
            "description": "",
            "status": "deployed",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "maybe split into ICP and other tokens"
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "ICRC-3 implementation for ICRC-1 ledgers",
            "overview": "Implementation of the ICRC-3 transaction log standard for the ICRC-1 ledger implementation and rollout to SNS, ckBTC, and ckETH ledger deployments.",
            "description": "The ICRC-3 standard needs to be implemented in the ICRC-1 ledger implementation. This enhances the ICRC-1 ledgers with a standardized way of accessing the block log. This affects all deployments of ICRC-1 ledgers, e.g., also the SNS token ledgers.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "final"
          },
          {
            "title": "Rosetta for ICRC ledgers",
            "overview": "Implement the Rosetta standard for ICRC-based ledgers. Enables ICRC tokens to be handled by centralized exchanges.",
            "description": "Rosetta is a quasi standard put forth by Coinbase for the integration of blockchain ledgers with centralized exchanges. Besides a Rosetta implementation for the ICP ledger, an implementation for ICRC ledgers using ICRC-3 as block storage format is implemented in the scope of this feature.",
            "status": "in_progress",
            "eta": "2024",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Andrea"
          },
          {
            "title": "Trust Wallet integration",
            "overview": "Integrating ICP with the widely-used Trust Wallet project. Can help adoption of ICP beyond the current audience.",
            "description": "Trust Wallet is a widely-used wallet integrating with a wide range of blockchain platforms. Integrating with Trust Wallet may help improve adoption of ICP. Integrating with Trust Wallet requires enabling the Trust Wallet Core library to sign ICP transactions, adding ICP to the Trust Wallet token repository, and providing a Rosetta node for them to access the ledger.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "IC-1614: https://dfinity.atlassian.net/browse/IC-1614"
          },
          {
            "title": "ICRC 4: Batch transfers for fungible tokens standard",
            "overview": "Extension standard for ICRC-1 defining batch transfers for ICRC-1 tokens. Batching transactions improves throughput and can reduce cost.",
            "description": "Some use cases of token ledgers such as token distributions or specifically airdrops can benefit from the added support of batch transactions by a ledger. A batch transaction allows the caller to batch a larger number of individual transactions into a single canister method invocation. This not only saves on cycles for the method call overhead, but also allows for drastically increasing throughput of the ledger, which would otherwise be constrained by the subnet's ingress of XNet capacity.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-21 canister call consent messages",
            "overview": "Standard for a protocol for obtaining human-readable consent messages for canister calls.",
            "description": "This specification describes a protocol for obtaining human-readable consent messages for canister calls. These messages are intended to be shown to users to help them make informed decisions about whether to approve a canister call / sign a transaction. The protocol is designed in such a way that it can be used interactively (e.g. in a browser-based signer) or non-interactively (e.g. in a cold signer).",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-22 payment request formats",
            "overview": "Standard for serializing payment requests for tokens on ICP as URL and thus also QR code.",
            "description": "This standard defines the format of URLs for expressing the parameters required for making payments. The URLs can be expressed as a QR code to realize a simple visual channel between devices, e.g., a payment terminal and a user's mobile device.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-7: Basic non-fungible token (NFT) standard",
            "overview": "Basic non-fungible token (NFT) standard for the Internet Computer featuring batch APIs.",
            "description": "ICRC-7 defines the basic NFT standard for the Internet Computer. ICRC-7 is a basic NFT standard for NFTs without a contained marketplace. The API is simple yet comprises batch functionality for higher throughput of operations for both query and update calls. This standard is expected to unify the NFT-related development on ICP and help clean up the fragmented NFT standards landscape.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "ICRC-37: Approve / transfer_from extension for ICRC-7.",
            "overview": "Approve / transfer_from extension for the ICRC-7 basic NFT standard for the Internet Computer. Simplifies many scenarios by avoiding error scenarios of regular transfers.",
            "description": "ICRC-37 extends ICRC-7 with approve and transfer_from semantics. This semantics is prominently usef for tokens in the Ethereum ecosystem and allows a token holder to approve a spender to transfer tokens on their behalf. The spender can, as long as an approval is valid, transfer tokens on behalf of their owner. This simplifies many use cases where certain errors otherwise make their handling tricky. Together with ICRC07, this standard is expected to help unify the NFT-related development on ICP and help clean up the fragmented NFT standards landscape.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Implement ICRC-21 in Ledger devices",
            "overview": "The implmentation of ICRC-21 in Ledger devices will allow us to support generic transactions.",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "IC-1577: https://dfinity.atlassian.net/browse/IC-1577"
          },
          {
            "title": "Chain-key token (ck token) support in the ICP wallet",
            "overview": "Support for chain-key tokens (ck tokens) in the ICP wallet.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "generic support for ck tokens in the wallet"
          },
          {
            "title": "Ledger Live staking integration",
            "overview": "Ledger live acquires the ability to stake ICP.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/GIX-2454"
          },
          {
            "title": "ICRC-7/-37 NFT standard in mobile wallets",
            "overview": "Bringing the ICRC-7 and ICRC-37 standards for NFTs on ICP to mobile wallets.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list"
          },
          {
            "title": "Fireblocks integration",
            "overview": "An integration of the Internet Computer blockchain with the Fireblocks custody provider to simplify ICP for institutionals.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Cycles ledger",
            "overview": "Ledger for cycles to allow non-canister principals to hold cycles. Simplifies the development workflow.",
            "description": "The cycles ledger is, as its name suggests, a ledger for cycles on ICP. Its purpose is to hide the limitation that non-canister principals cannot hold cycles in the context of canister development. With the cycles ledger, developers do not need the hard-to-handle and unintuitive concept of cycles wallets any more, but charge cycles into the cycles wallet instead. This creates the impression w.r.t. the developer workflow that the developer principal used to deploy canisters holds cycles itself.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Ledger metrics",
            "overview": "This feature collects and exposes certain metrics of ledgers on the Internet Computer. Both the ICP ledger as well as ICRC-1/-2/-3 ledgers receive metrics support.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "?? details"
          },
          {
            "title": "More tokens on Coinmarketcap",
            "overview": "More of the tokens in the ICP ecosystem should become listed on Coinmarketcap.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": ""
          }
        ]
      }
    ]
  },
  {
    "name": "Governance",
    "description": "Community-driven governance for both the ICP platform as well as dapps.",
    "milestones": [
      {
        "name": "Liquid democracy V2",
        "description": "The next big step for ICP's governance: Make more information on voting activity of named neurons available and increase active DAO participation. This is achieved by a multi-faceted approach: Enabling governance participants to provide more information about their future voting behaviour to make it easier for followers to decide on whom to follow; encourage the diligent active voting of neurons; making information on SNS DAOs readily available in a communities portal; and simplify the following experience for more diverse following requirements. Better transparency and increased active voting participation. This milestone boosts the excellency in active governance participation.",
        "milestone_id": "Titanium",
        "eta": "2025-03",
        "elements": [
          {
            "title": "Engagement platform for named neurons",
            "overview": "Make information about named neurons’ voting behavior easily accessible for voters to make informed decisions who to follow.",
            "description": "Name neurons can register in the NNS so that other neurons can find them and follow them on some proposal topics. While their names and the last few ballots can be found by their followers, additional context is often missing. This feature is to facilitate a more engaged community, where named neurons can share more information that can then be used by potential followers to make well-informed decisions. For example, this could include the (future) voting intentions of named neurons, for example whether they always intend to vote on certain topics and what values they generally support, some context on why the named neurons voted in a certain way and more accessible voting history of the named neurons.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Titanium",
            "notes": ""
          },
          {
            "title": "Increase and facilitate active participation in SNS DAOs",
            "overview": "Further increase voting activity in the SNS DAOs by introducing an easy way to find experts and follow them.",
            "description": "Unlike the NNS, there is currently no notion of named neurons in the SNSs. Therefore it is harder for users to find actively voting neurons that they can follow. The goal of this feature is to change this and make it easier for actively voting neurons to identify themselves and for other users to find and follow them.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Titanium",
            "notes": ""
          },
          {
            "title": "Encourage diligent active voting",
            "overview": "Further increase voting participation of neurons that make well-founded, informed decisions.",
            "description": "Improve the experience for neurons to make well-founded, informed decisions. For example, make it easier for named neurons to fully commit to always voting on some topics. This enables new neurons to become experts on some topics and may then be followed by other neurons. Since following is done based on proposal’s topics, one way to achieve this is to reorganize topics so that they can reasonable by covered by individual named neurons.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Titanium",
            "notes": ""
          },
          {
            "title": "SNS communities portal",
            "overview": "Introduce a landing page for each SNS DAO to the NNS dapp to foster the DAO communities.",
            "description": "This feature has the goal to improve the experience on the NNS dapp to create a sense of community for the individual SNS DAOs and make all information concerning one DAO more readily accessible. To achieve this, one could introduce a new landing page for each SNS DAO which includes a summary of the DAO, for example the name and a description, but also summarizes the actionable proposals where a logged-in user can still vote on and links to the user’s neurons in that SNS.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Titanium",
            "notes": ""
          },
          {
            "title": "Simplify neuron following experience",
            "overview": "Simplifications of neuron following in the NNS and SNS to enhance UX for governance participants.",
            "description": "Today, it is quite cumbersome to set up several neurons at the same time, especially in cases where a user intends to follow a more diverse set of neurons based on the proposal topic. This is because neuron following is saved each time it is set for a topic. A potential solution would be to allow the user to create a followee setup, and save it once they are happy with it, or even do batch neuron actions. Another goal is to improve the NNS dapp so that special cases for proposal following become intuitively visible, for example if some proposals are not covered by the “catch-all” following or are categorized as critical.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "milestone_id": "Titanium",
            "notes": "named neurons, batch configs; ?? Jan: what exactly is meant here, we may better switch to another model; Björn T: SNS painful to use for investor; on-chain following was stop-gap solution; should not have been encoded on chain; pushing towards tooling to not require on-chain following; Q: how important? right thing to make it less painful if there's another solution coming? within SNS, not across SNS probably; now: all neurons with short dissolve delay (DD) follow the one with long DD; only need to configure those with long DD; batch not so important for this reason; for NNS have named neurons; for SNS no convention; batch is not a strong tool to solve this"
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "NNS FE Dapp Re-write",
            "overview": "Replacing Flutter with Svelte for the NNS Frontend dapp. Significant speed and UX improvements expected.",
            "description": "The NNS FE dapp introduced at genesis was built on Flutter with mediocre usability. This feature replaces Flutter with Svelte — a technology stack better suited for the Internet Computer. The replacement led to significant improvements in dapp speed and user interface.",
            "forum": "https://forum.dfinity.org/t/nns-dapp-towards-new-ui-ux-including-test-link/13952",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "July 2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "NNS spam protection (remove financial incentive)",
            "overview": "Protecting the NNS against proposal spam by removing the financial incentive for such spam by allocating voting rewards differently.",
            "description": "This roadmap item is based on the community proposal 80970. <br><br> In the current voting reward set-up, there is a financial incentive for spam because the overall reward pot is always handed out and by submitting governance spam propoals you can skew the voting reward allocation.  <br><br> This change removes this incentive by allocating voting rewards under the assumption that every neuron voted on everything.  <br><br> This change also includes moving the governance weight back to 20 and the tracking of allocated vs not allocated voting rewards.",
            "forum": "https://forum.dfinity.org/t/reproposal-spam-prevention-convert-from-system-based-rewards-to-voter-based-rewards/15352/1",
            "proposal": "https://dashboard.internetcomputer.org/proposal/80970",
            "wiki": "",
            "docs": "",
            "eta": "Q1 23",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Carbon Footprint and Sustainability Policy",
            "overview": "Conducting a carbon footprint / environmental impact assessment of ICP. Footprint of a subnet, source of electricity, total environmental cost of a tx on ICP.",
            "description": "This roadmap item is based on the community proposal 55487. <br><br> Step 1: Conduct a carbon footprint / environmental impact assessment — either through internal resources or hiring an external consultant to answer basic questions about what the carbon footprint of running an IC Subnet is, where that electricity is sourced, and what the total cost per transaction is on the IC blockchain. Based on the learnings define more activities. <em>Update:</em> The Internet Computer Footprint Report is now available [here](https://assets.carboncrowd.io/reports/ICF.pdf). <br><br> Step 2: “Energy consumption” reporting panel to the IC Network Status dashboard.  Update: Power/Energy consumption is now reported in real time on the IC Dashboard homepage, as well as individually for given nodes, see example node [here](https://dashboard.internetcomputer.org/node/25p5a-3yzir-ifqqt-5lggj-g4nxg-v2qe2-vxw57-qkxtd-wjohn-kfbfp-bqe). Carbon Crowd also launched a [Sustainability Dashboard](https://app.carboncrowd.io/).",
            "forum": "https://forum.dfinity.org/t/sustainability-nns-proposal/11976",
            "proposal": "https://dashboard.internetcomputer.org/proposal/55487",
            "wiki": "",
            "docs": "",
            "eta": "Q2 23",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Service Nervous System (SNS)",
            "overview": "A DAO factory that allows for proposal-based no-code creation of a DAO, including an initial decentralization swap. Available as part of the ICP governance framework.",
            "description": "This SNS rollout will include several features: **1.** SNSs that are provided as a protocol function (deployed on an SNS subnet and facilitating maintainable upgrades), **2.** A first version of voting rewards for SNSs that can be further customised in the future, **3.** Decentralization swaps that decentralize a dapp, where participants provide ICP tokens in exchange for SNS tokens. **4.** A NNS frontend dapp extension that allows end users to participate in the decentralization swap. **5.** Tooling to help users initialize an SNS.",
            "forum": "",
            "proposal": "https://dashboard.internetcomputer.org/proposal/65132",
            "wiki": "",
            "docs": "",
            "eta": "Q1 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Community Fund",
            "overview": "A first version of a community fund that provides means for the NNS community to have a \"treasury\" to invest in projects on ICP.",
            "description": "This feature implements a first version of a community fund that provides means for the NNS community to have a \"treasury\" to invest in projects on the Internet Computer. In this first version neurons which have enabled the “community fund” feature may expose their maturity to the decisions of the NNS to invest in SNS decentalization swaps. Note: This feature has been renamed to “Neuron's Fund” later.",
            "forum": "https://forum.dfinity.org/t/community-fund-revised-design-proposal/14691",
            "proposal": "https://dashboard.internetcomputer.org/proposal/74820",
            "wiki": "",
            "docs": "",
            "eta": "Q1 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Restriction for SNS swap participation",
            "overview": "Constraining participation in decentralization swaps of SNSs based on geographic location. Includes custom disclaimers to be confirmed by users before participating.",
            "description": "When an SNS is launched, it goes through a decentralization swap. During the swap, participants provide ICP and in return receive a share of the SNS DAO’s governance power in the form of SNS neurons. In the current design, swaps are open for anyone to participate. <br><br> Different projects in the community have requested a feature that allows SNSs to restrict participation in the swap by geographic location. In addition, this feature enables swap participants to be presented with a custom confirmation text that they need to confirm before being allowed to participate.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "One-proposal SNS initialization",
            "overview": "Simplifying decentralization of a dapp from two NNS proposals plus manual steps to a single proposal.",
            "description": "Currently, the process of decentralizing a dapp through the SNS platform requires two NNS proposals plus a few manual steps. Once this feature is implemented, the creation of a SNS will be done by a single proposal which the NNS community votes on.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Neurons' Fund Enhancements: Matched Funding",
            "overview": "Enhancing the Neuron's Fund, e.g., to scale with swap participation by the community or having a 10% cap on participation.",
            "description": "Based on collected experience and community feedback from recent SNS launches and forum discussions, we propose four enhancements to the Community Fund framework: <br><br> Introduction of a ‘Matched Funding’ scheme: Instead of a fixed ICP amount, the fund’s contribution to SNS swaps should scale in line with direct participation, i.e., match the funding of the Neuron's Fund with the organic funding received during the SNS launch, allowing for a more accurate reflection of market signals. <br><br> Implementation of a 10% Participation Cap: To streamline adjustments when neurons opt out during SNS proposal voting, we suggest a cap in relationship to the totals funds available. This ensures the fund’s contribution to a single SNS never exceeds 10% of the total available funds at the proposal execution time. Consequently, this automatically adjusts the fund’s participation if neurons opt out. <br><br> Renaming of the ‘Community Fund’ to ‘Neurons’ Fund’: This change aims to clarify misconceptions about the fund. It emphasizes that the fund comprises neurons owned by private individuals who are exposing their maturity to promising SNS DAOs. It is suggested to release this cosmetic change next week. <br><br> Reduction of the Maximum Swap Duration: A potential fund contribution is tied up and cannot be utilized for other SNS launches for the duration of the swap. To prevent a potentially unsuccessful swap from blocking a fund contribution for an extended period, we propose shortening the maximum swap duration from the current 90 days to 14 days.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "December 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Ability to mint SNS tokens and revised thresholds for voting",
            "overview": "",
            "description": "Some SNS projects have requested SNS token minting functionality to fine tune the DAO's tokenomics. This feature implements token minting for SNS projects. In addition, this feature defines some of the SNS proposals as critical and increases their voting thresholds. See the forum link for the details.",
            "forum": "https://forum.dfinity.org/t/new-sns-ability-to-mint-sns-tokens-revised-thresholds-for-voting/23382",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 24",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Node Provider Remuneration V2",
            "overview": "The remuneration scheme v2 improves on the original v1 scheme by reducing remuneration for regions having already many nodes and reducing also for additional nodes of a node provider.",
            "description": "For the further growth of the IC network, the NNS agreed on a new replica hardware specification. The new specification is generic, i.e. not vendor specific. It is ready for upcoming ICP improvements. For example, it supports VM memory encryption and attestation which will further increase the security of dapps running on ICP. The new specification results in different captical expenses for the independent node providers running replica nodes. Consequently, a new NP reward structure (remuneration) is required. Based on feedback and discussion within the community, this remuneration is based on: — Higher rewards for the first nodes of a new NP in order to attract more NPs in an effort to improve ownership decentralization. — More refined rewards for nodes in new geographies, like South America, Africa, Asia and Australia, to stimulate further geographical decentralization. <br><br> IC wiki: https://wiki.internetcomputer.org/wiki/Node_Provider_Remuneration",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "?? is this deployed yet; IC-1493: https://dfinity.atlassian.net/browse/IC-1493; New Node Provider remuneration scheme for the 2nd gen hardware: Higher rewards for first nodes, more refined rewards for new geographies.",
            "imported": true
          },
          {
            "title": "Enable ICRC-2 for SNS ledgers",
            "overview": "Update the SNS framework to enable the rollout of ICRC-2 on the SNSs’ ledger canisters.",
            "description": "",
            "status": "deployed",
            "eta": "Q1 2024",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "this is about the rollout of the feature in SNS ledgers, not the implementation, which is separate"
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Visual indicator of actionable proposals in the NNS dapp",
            "overview": "Users will see a ‘notification’-like indicator in the NNS dapp next to the name of different projects that show how many open governance proposals there are that the user can vote on.",
            "description": "Users will see a ‘notification’-like indicator in the NNS dapp next to the different projects that show how many open governance proposals there are that the user has eligible neurons to vote on. This allows users to quickly get a glance of all the proposals that they can still vote on, instead of having to click through every project that may have open proposals.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Increase reward for SNS launch proposals to 20",
            "overview": "Increase the reward weight of NNS proposals of topic \"SNS & Neuron’s Fund\" to 20 to incentivize more active voting and have the same rules as for proposals of topic \"Governance\"",
            "description": "",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Periodic Confirmation of Neuron Followees",
            "overview": "Require neuron owners to confirm their neurons’ following settings periodically.",
            "description": "This roadmap item is based on the community proposal 55651. <br><br> Caveat: A periodic reconfirmation of neuron following would presumably (at least initially) result in an active voting power of below 50% for non-governance topics. Thus, even if all voters voted, the system would have to wait for the end of the voting period, which is problematic in case of urgent updates (e.g. update of a subnet). This limitation needs to be mitigated.",
            "forum": "https://forum.dfinity.org/t/periodic-confirmation-of-neuron-followees/12109",
            "proposal": "https://dashboard.internetcomputer.org/proposal/55651",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Governance portfolio reporting capabilities",
            "overview": "Reporting functionality that allows users to obtain summary information about their neurons.",
            "description": "Currently, it is difficult for users to obtain detailed historic information on received voting rewards and the neuron spawning history. In practice, users need to manually track their actions periodically or use third-party canisters to obtain this information. This feature enables ICP to provide reports to users regarding voting rewards and neurons",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Allow ecosystem wallets to connect to the NNS dapp",
            "overview": "Allow ecosystem wallets to control tokens and governance neurons in the NNS dapp to foster an interoperable ICP ecosystem.",
            "description": "The ICRC signer standards are being developed in collaboration with the ICP community to enable secure, and standardized communication between canisters. Adopting ICRC signer standards will foster an ecosystem of ICP dapps where the end-user has full control over their tokens, while managing them across dapps is much simplified. The NNS dapp will open up and provide an example implementation using these standards to allow ecosystem wallets to control assets in the NNS dapp. ICP wallets and dapps are encouraged to follow suit and together create an interoperable ICP ecosystem.",
            "status": "upcoming",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Simplification of NNS neurons",
            "overview": "NNS neurons have different properties, such as dissolve delay and age. Some of these properties must be in a certain relation at all times. This feature is to abstract away more of these details from the users so that neurons are easier to understand.",
            "description": "",
            "status": "future",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "NNS Neuron ID Indexing",
            "overview": "Create an index of all neuron ID values, accessible through a public interface.",
            "description": "This roadmap item is based on the community proposal 48491.",
            "forum": "https://forum.dfinity.org/t/motion-request-for-neuron-indexing/11183",
            "proposal": "https://dashboard.internetcomputer.org/proposal/48491",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Manual overwriting of following-triggered votes",
            "overview": "This feature enables manually (overwrite) voting throughout the entire voting period of governance proposals even when a neuron is following another neuron.",
            "description": "This roadmap item is based on the community proposal 38985.",
            "forum": "https://forum.dfinity.org/t/proposal-to-enable-manual-voting-throughout-the-entire-voting-period-of-governance-proposals/9815",
            "proposal": "https://dashboard.internetcomputer.org/proposal/38985",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Improve staking user experience",
            "overview": "Simplify and make the ICP staking process self-explanatory in the NNS dapp to eliminate barriers of entry for first-time users.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": false
          },
          {
            "title": "More diverse NNS proposal verification",
            "overview": "Involve more community participants in the verification of proposals and incentivize them for their efforts.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "?? relates to the new active neurons item"
          },
          {
            "title": "Archiving of NNS proposals",
            "overview": "Storing NNS proposals long term instead of deleting them after a defined time period as done currently to increase transparency and accountability of governance.",
            "description": "Currently, NNS proposals are only kept for a limited time and are then deleted. This feature intends to archive governance proposals to enhance transparency and accountability of the governance system.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Maintain neurons’ voting history",
            "overview": "Keeping the voting history of all neurons for better transparency and accountability of ICP governance.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Private voting",
            "overview": "Private voting of neuron holders. This helps prevent leakage of information on how neurons voted to ensure that neuron holders can vote freely without fearing consequences.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "changed to private voting instead of using voting protocols; verifiable, ...; Interesting particularly for whales to not reveal their voting behavior to everyone. Björn T: cryptographically anonymous voting; don't see this to be done in the near future"
          },
          {
            "title": "Financial reporting",
            "overview": "Reporting functionality that allows users to obtain summary information about their neurons.",
            "description": "Currently, it is difficult for users to obtain detailed historic information on received voting rewards and the neuron spawning history. In practice, users need to manually track their actions periodically or use third-party canisters to obtain this information. This feature enables ICP to provide reports to users regarding voting rewards and neurons.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Make proposals easier to understand",
            "overview": "Easier-to-understand proposals, e.g., through an AI bot.",
            "description": "Easier-to-understand proposals, e.g., through an AI bot. The details of whether and how this can be realized are still to be worked out. There are examples of other protocols on using AI to achieve this.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "?? Sam: rather remove; way too many proposals, not realistic that someone reads them; now people follow; just this is not enough; rather do something like parties; make more concrete or remove; community list; e.g., use AI to summarize a proposal and drill down interactively"
          },
          {
            "title": "Neuron instant dissolve functionality",
            "overview": "Instantly dissolving a neuron to access a fraction of the locked-up tokens immediately.",
            "description": "Instantly dissolving a neuron and recovering a fraction of the locked-up value allows a neuron holder to obtain part of the tokens today instead of having to wait until the dissolving has completed to be able to obtain all locked tokens. This tradeoff may be valuable for stakeholders in certain circumstances.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "?? Do we want to have this on the public roadmap?"
          },
          {
            "title": "Safeguards for critical SNS proposals, including the SNS treasury",
            "overview": "Additional safeguards for transferring funds from an SNS treasury.",
            "description": "Some SNS proposals are more critical than others in that they have a big impact. This feature introduces additional measures to make it harder for them to be adopted, such as requiring a higher approval threshold. In addition, this feature introduces limits for treasury and minting proposals.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 2024",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "https://dfinity.atlassian.net/browse/IC-1663",
            "imported": true
          },
          {
            "title": "Visual indicator of actionable proposals in the SNS dapp",
            "overview": "Users will see a ‘notification’-like indicator in the NNS dapp next to the name of different projects that show how many open governance proposals there are that the user can vote on.",
            "description": "Users will see a ‘notification’-like indicator in the SNS dapp next to the different projects that show how many open governance proposals there are that the user has eligible neurons to vote on. This allows users to quickly get a glance of all the proposals that they can still vote on, instead of having to click through every project that may have open proposals.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "SNS cycles management",
            "overview": "Support better automation of top-up of cycles for SNS and SNS-managed canisters for better usability.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": false,
            "in_beta": false,
            "notes": "SNS canister have automated top-up of cycles and similar ideas"
          },
          {
            "title": "Neuron fund phase II (end of investment)",
            "overview": "Addresses the end-of-investment phase of the Neuron's Fund.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "not even the idea what should happen here is clear"
          },
          {
            "title": "Hide 0 balances for SNS tokens/neurons",
            "overview": "Allow users to hide all projects from the list that they have 0 tokens or neurons in. This will make the UI cleaner, and provide a better overview of DAOs the user cares about.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": false
          },
          {
            "title": "Improve staking user experience",
            "overview": "Simplify and make the SNS staking process self-explanatory in the NNS dapp to eliminate barriers of entry for first-time users.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": false
          },
          {
            "title": "Update of SNS ledger parameters",
            "overview": "Enables parameters of SNS ledgers, such as the SNS token name, to be updated through SNS upgrade proposals.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "contested whether all ledger parameters should be updateable via proposals; ICRC-2 enabling clearly wanted"
          },
          {
            "title": "SNS swap participation with additional tokens",
            "overview": "Allow users to participate in SNS decentralization swaps with different tokens than ICP, e.g., ckBTC or ckETH. Also a combination of tokens may be applicable.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Standalone \"SNS\" DAO",
            "overview": "Allow creating a DAO using the SNS governance code, but without going through an NNS proposal, without NNS orchestration, and without the DAO canisters being deployed on the SNS subnet.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Simplified SNS life cycle",
            "overview": "Enhancements to the SNS life-cycle to improve the experience of SNS canister upgrades for SNS communities, e.g., through API versioning and better auditability of error messages on failed upgrades.",
            "description": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "change token name moved to other item, better upgrades of SNS canisters; Björn T: assumes it's about cases where upgrade fails; hard to handle failures; must do specific upgrade paths for individual projects; much handholding required currently for upgrades; hard to recover when upgrade process goes wrong; need to build specific upgrades to recover; works, but hard operationally; ask Lara"
          },
          {
            "title": "Improved node provider reward scheme",
            "overview": "Improved reward scheme for node providers taking into consideration their useful work, i.e., quantifiable contributions to the network as well as (un)availability.",
            "description": "The current node provider rewards are largely based on capital and operational expenses of node providers and the cost structure of their geography. This feature intends to shift the reward scheme towards a scheme that rewards contributions to the network in terms of useful work performed as measured securely by the protocol. This makes node provider rewards be directly based on quantifiable contributions to the ICP network. This feature builds upon the trustworthy metrics of nodes for useful work performed.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "uses metrics of https://dfinity.atlassian.net/browse/IC-1591"
          }
        ]
      }
    ]
  },
  {
    "name": "Developer experience (DX)",
    "description": "Ensuring a seamless developer experience for ICP and all new features.",
    "milestones": [
      {
        "name": "Simplified canister development &amp; operations",
        "description": "Canister development and operations is simplified by improved canister logging and error handling, canister snapshot capabilities, and cycles consumption insights. This helps streamline the way you develop and manage your canister smart contracts of your dapp during the whole life cycle.",
        "milestone_id": "Nickel",
        "eta": "2024-10",
        "elements": [
          {
            "title": "Canister snapshots",
            "overview": "Allow for canister snapshots to be created on chain. Snapshots can be exported to and imported from off-chain storage.",
            "description": "Data of canisters on ICP can currently not be easily exported by its controller, or exported data imported into another canister. Such functionality can be written by the canister developer, but should rather come as a platform feature of ICP. This feature brings snapshotting capabilities for canisters, the export of the snapshot to the off-chain world, and import of snapshots back into a canister.",
            "status": "in_progress",
            "forum": "https://forum.dfinity.org/t/canister-backup-and-restore-community-consideration/22597",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Nickel",
            "notes": "final; reviewed by Dimitris"
          },
          {
            "title": "Canister logging",
            "overview": "New APIs for writing and reading canister runtime logs.",
            "description": "This allows a developer to store and retrieve runtime logs of canisters deployed to mainnet through a dedicated memory buffer. The logs survive upgrades and traps and ensure developers are able to record key error data.",
            "forum": "https://forum.dfinity.org/t/canister-logging/21300",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "status": "upcoming",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Nickel",
            "notes": "final; reviewed by Jason; community list: https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/51",
            "imported": true
          },
          {
            "title": "Canister lifecycle hooks",
            "overview": "Push model for canisters receiving notifications from the ICP, e.g., when they are low on cycles. More resource efficient than periodic pulling.",
            "description": "Currently, developers have to actively monitor their canisters by periodically polling the cycle balance and the memory usage of the canisters. Periodic polling is inefficient in terms of resource usage and difficult to maintain for dapps with many canisters. This feature aims to improve the monitoring and observability of canisters by introducing a push model, where the canister is automatically notified when it is low on cycles and memory.",
            "forum": "https://forum.dfinity.org/t/canister-lifecycle-hooks/17089",
            "proposal": "https://dashboard.internetcomputer.org/proposal/106146",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "upcoming",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Nickel",
            "notes": "final; Ulan: lgtm",
            "imported": true
          },
          {
            "title": "Standardized canister response codes",
            "overview": "Standardize canister response standard, particularly error codes, to enable better composability of services from canister smart contracts.",
            "description": "",
            "status": "upcoming",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Nickel",
            "notes": "community list (Jordan Last)"
          },
          {
            "title": "Cycles consumption insights",
            "overview": "Give canister controllers insights on cycles consumption of their canisters.",
            "description": "Tracking down where cycles are consumed during the operation of a canister is currently a tedious job requiring manual efforts. This feature provides people who operate canisters insights into where cycles were spent. These insights can be used to optimize the cycles consumption of canisters.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "milestone_id": "Nickel",
            "notes": "",
            "imported": true
          }
        ]
      },
      {
        "name": "orphans_past",
        "description": "Orphans from the past",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Bitcoin Integration with DFX",
            "overview": "Configure and run a Bitcoin adapter on the dev machine supporting the development with the native Bitcoin integration.",
            "description": "This feature allows developers to spin up a Bitcoin adapter in dfx that connects to a Bitcoin node running on the developer's machine. Configuration parameters in dfx.json specify how to connect to the Bitcoin daemon.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "August 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "dfx Deps",
            "overview": "Enable canister developers to pull third party canisters into their local environment in order to build integrations that would otherwise require building code from source.",
            "description": "dfx deps allows canister developers to pull third party canisters into their local environment in order to build integrations that would otherwise require building code from source.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "DFX Quickstart",
            "overview": "New command that guides the developer through the steps necessary to ensure a successful deployment to mainnet.",
            "description": "This feature introduces a new command that guides the developer through the steps necessary to ensure a successful deployment to mainnet. It also serves up useful information, such as the developer's current identity, ICP balance, the list of locally running canisters (future), and more.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 23",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Asset Caching",
            "overview": "Enable caching of assets served by the asset canister by giving it time-to-live information.",
            "description": "Boundary nodes only cache queries for a very short amount of time. Assets (HTML pages, JS sources, images, etc) are not cached. The asset canister does not provide TTL information as to when the assets should expire. This feature gives the assets time-to-live information and expose it on the boundary nodes as well as the service worker.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 22",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "SNS Quill",
            "overview": "Provides all the commands developers need to build and interact with an SNS. Based on the original Quill project.",
            "description": "SNS Quill provides all the commands developers need to build and interact with an SNS both locally and on mainnet. It is based on the original Quill project, and will be integrated back into Quill at a future date.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "August 2022",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "System-wide DFX",
            "overview": "Allows for running dfx as a system-wide process instead of being project specific. Makes it easier to start and stop canisters, run tests, and develop integrations.",
            "description": "Today, the execution environment provided by dfx is project specific. This feature removes this limitation and allows developers to run dfx as a system-wide process. This quality-of-life improvement will make it easier to start and stop canisters, run tests, and develop integrations. Available in DFX 0.12.0.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "November 2022",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "DFX keyring integration",
            "overview": "This feature integrates DFX with the OS keyring for seamless decryption of password-protected identities.",
            "description": "This feature integrates DFX with the OS keyring for seamless decryption of password-protected identities.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 22",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "SNS Tooling",
            "overview": "Enhance dfx for developing testing dapps for SNS-based decentralization. Code and test a swap locally, simulate it on mainnet, and manage a dapp after launch.",
            "description": "We want to enable more developers to decentralize their dapps through the SNS. dfx now has more tools and capabilities for you to develop your code and test your swap locally, run a simulated swap on mainnet, and manage your dapp after it has been launched.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "PocketIC",
            "overview": "The PocketIC is a canister testing system that allows to run a \"pocket version\" of ICP, including multiple subnets. This is the preferred way of testing dapps.",
            "description": " is a system for testing canisters.  is spun up on a developer's machine and behaves similarly to the IC mainnet. It provides a shortcut to the IC's execution environment, stripping away the networking and consensus layers, while the execution environment is the same that executes canisters on mainnet. It supports multiple subnets, thus offers a powerful platform for testing dapps efficiently.  is intended to become the preferred solution for testing canisters.",
            "forum": "https://forum.dfinity.org/t/pocketic-testing-canisters-in-python/22490",
            "proposal": "",
            "wiki": "",
            "docs": "https://internetcomputer.org/docs/current/developer-docs/setup/pocket-ic",
            "eta": "Dec 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Jason; no consensus, no round times; fast for testing; goal: replace replica in DFX with ; DFX is full replica incl. consensus incl. artificial delay;  is execution environment; https://dfinity.atlassian.net/browse/IC-1538"
          },
          {
            "title": "Improved Unit Testing for Motoko",
            "overview": "Brings a number of enhancements to unit testing in Motoko: Support for watch mode, VSCode extension GUI, and more.",
            "description": "This brings a number of enhancements to unit testing in Motoko, including support for watch mode, VSCode extension GUI, and more. See the PR [here](https://github.com/dfinity/motoko-base/pull/527)",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 23",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "React Native Starter Template",
            "overview": "A starter project template for React Native comprising Agent-JS for an integration with ICP.",
            "description": "This feature provides a starter template to use as the basis of an integration between React Native, Agent-JS, and the IC that developers can use to build fully native mobile apps for the Internet Computer.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 22",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Motoko Base Library Enhancements",
            "overview": "Community-requested data structures and functionality for the Motoko Base Library.",
            "description": "This feature brings long sought after data structures and functionality to the Motoko Base Library. Additions and enhancements to the Motoko Base Library will be ongoing and recurring as a set of quarterly deliverables.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 22",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Motoko Incremental Garbage Collector",
            "overview": "Blazing fast new garbage collector (GC) for Motoko, based on incremental GC.",
            "description": "We are redesigning Motoko's garbage collector to be blazing fast. We're utilizing a design known as an incremental garbage collector to achieve considerable performance improvements. This is a large effort, and we currently expect the new garbage collector to be available towards the end of 2023.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 23",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Motoko Formatter & VSCode Extension",
            "overview": "Better dev UX for Motoko in VSCode. Motoko formatter, prettier integration, and other VSCode extensions.",
            "description": "This feature brings significant enhancements to the Motoko developer experience with a new and improved formatter, prettier integration, and numerous new features to the VSCode extension.",
            "forum": "https://forum.dfinity.org/t/we-heard-you-motoko-vs-code-extension-improvements/15933",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 22",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Motoko let-else Binding",
            "overview": "A let-else binding allows a failure block to be run in case of a binding failure. Avoid deeply nested switch statements and have more readable code.",
            "description": "This Motoko language feature allows a failure block to be run in case of a binding failure. The main motivation for this feature is to avoid deeply nested switch statements that lead to less readable code.",
            "forum": "https://forum.dfinity.org/t/solution-in-moc-0-8-3-let-else-match-and-take-in-motoko-do-for-variants-was-when/13427/6",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 23",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Motoko Dev Server",
            "overview": "Live-reload environment for Motoko projects that allows for rapid prototyping and a friction-free development experience.",
            "description": "The motoko-dev-server is a live-reload environment for Motoko projects that allows for rapid prototyping and a friction-free development experience.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "New project builder and templates",
            "overview": "More powerful workflows for creating new projects using dfx new.",
            "description": "The dfx project builder (dfx new) will receive a redesign that includes an improved UI, additional and updated templates, and more configuration options",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 2024",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Jason; https://dfinity.atlassian.net/browse/IC-1582",
            "imported": true
          },
          {
            "title": "Motoko Stable Regions",
            "overview": "Run-time-based stable memory data structures allocating memory in multiple different regions. Improves Motoko's stable memory support towards towards composable use cases.",
            "description": "The current stable memory module in base has been \"experimental\" for a long time, and requires a more composable API to graduate from this status. <br><br> Stable regions address the problem that today's ExperimentalStableMemory module only provides a single, monolithic memory that makes it unsuitable for directly building composable software parts. <br><br> Stable regions permit a new API that supports composable use cases. <br><br> Stable regions also bring Motoko closer to parity with Rust canister development support today, by giving a run-time-system-based analogue of a special Rust library for stable data structures that allocates “pages” for them from stable memory in separate memory regions.",
            "forum": "",
            "proposal": "https://github.com/dfinity/motoko/blob/113f9c72edf4ff36bcc6dacc892fdb2f454ac81d/design/StableRegions-20230209.md",
            "wiki": "",
            "docs": "",
            "eta": "Q3 2023",
            "status": "deployed",
            "is_community": false,
            "in_beta": false,
            "notes": "",
            "imported": true
          },
          {
            "title": "Chunked upload of large Wasm files in dfx",
            "overview": "DFX support for uploading large Wasm files in chunks to meet message size limits. Complements replica support for large Wasm files.",
            "description": "DFX now supports uploading canister Wasm files up to 10MB in size. This is accomplished by splitting large modules into chunks less than 2MB in size, uploading all of the chunks, and then combining them on the backend to form a completed wasm.",
            "forum": "https://forum.dfinity.org/t/allow-installation-of-large-wasm-modules/17372",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q1 2024",
            "status": "deployed",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason; community list"
          }
        ]
      },
      {
        "name": "orphans_future",
        "description": "Orphans from the future",
        "milestone_id": "none",
        "eta": "none",
        "elements": [
          {
            "title": "Cycles Ledger",
            "overview": "The Cycles Ledger replaces the cycles wallet as the recommended solution for managing cycles across projects.",
            "description": "The Cycles Ledger replaces the cycles wallet as the recommended solution for managing cycles across projects. Prior to the development of the Cycles Ledger, the Cycles Wallet had been a source of confusion for many newcomers in the ecosystem. It is not a critical path for developing dapps on the Internet Computer and requires extensive prerequisite knowledge in order to be used effectively. Going forward, dfx will use the Cycles Ledger to make it simpler for developers to deploy code to the mainnet. The Cycles Wallet project will be deprecated in dfx, but developers will still be able to install and use it manually.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason",
            "imported": true
          },
          {
            "title": "dfx Version Manager",
            "overview": "The dfx version manager installs and manages versions of dfx.",
            "description": "Developers sometimes need to use different versions of dfx. They may be upgrading to a new version of dfx, testing their project with a beta of an upcoming dfx release, or evaluating someone else’s project that specifies a particular dfx version. The dfx version manager (dfxvm) installs and manages dfx installations. This also paves the way to support package manager installs of dfx in the future.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q2 2024",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "?? done; final; reviewed by Jason; https://dfinity.atlassian.net/browse/SDKTG-7",
            "imported": true
          },
          {
            "title": "dfx extensions",
            "overview": "Plugin architecture for integrating 3rd-party functionality directly into DFX.",
            "description": "The ability to extend the capabilities of dfx through an extension system would allow for myriads of integrations including CDKs, the Service Nervous System, Wallets, and more.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 2024",
            "status": "in_progress",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason",
            "imported": true
          },
          {
            "title": "dfx ergonomics",
            "overview": "Better developer experience when using the ICP SDK.",
            "description": "Ergonomic and quality-of-life improvements to dfx, simplifications, and reduction of manual effort.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason; DFX new: IC-1582: https://dfinity.atlassian.net/browse/IC-1582; dfx new: https://docs.google.com/document/d/1-heMmkTud1Oi0gVDhWp04duXMZHEfVlz4e8gxlRg8PM/edit#heading=h.zgq3j2p4c23t; DFX extensions: SDK-826: https://dfinity.atlassian.net/browse/SDK-826; probably split"
          },
          {
            "title": "Tutorials",
            "overview": "More and improved tutorials for faster successful onboarding of devs into the ICP ecosystem.",
            "description": "Tutorials for developers are crucial for new and seasoned developers alike. The experience for newcomers can be refined by having easy-to-follow and effective tutorials, in written and video form.",
            "status": "in_progress",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason"
          },
          {
            "title": "Motoko orthogonal persistence",
            "overview": "Offering simple and scalable persistence across upgrades without needing to use stable memory in Motoko.",
            "description": "Motoko already offers orthogonal persistence where objects are automatically retained across upgrades if reachable from stable variables. This simple-to-use and safe model will now be made as scalable as stable memory, by implementing instantaneous upgrades without serialization to and from stable memory and by allowing the same amount of orthogonally persistent data as with stable memory. For this purpose, the main memory obtains a self-descriptive format that can be retained across upgrades, while its address space is extended to 64-bit to pass the 4GB data limit.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "in_progress",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc; IC-1635: https://dfinity.atlassian.net/browse/IC-1635; design doc: https://docs.google.com/document/d/10j2Uaq7-Q8S0rI836j3_kUVk2bktPHLVpr-0vVsk6Zs/edit; Luc: stable variables: regular state of program is automatically persisted; whole main memory (RAM) would be persistent; compiler needs to handle if data representation changes; already have stable persistence now, ser/deser automatic, only takes time and can hit cycles limit; idea: don't need to serialize/deserialize any more; no limits, scales arbitrarily; also 64-bit addresses; don't need stable memory; the runtime systems checks upgrade compatibility and prevents memory corruption by incompatible upgrades. Some simple migrations are automatically supported. More complex data structure changes require manual migration."
          },
          {
            "title": "Streaming support for the Asset Canister",
            "overview": "Streaming specific byte ranges of large files hosted by the Asset Canister.",
            "description": "While the Asset Canister supports storage of up to 400 GB of assets, it does not yet have the capability to fetch specific ranges of content for a given file. By supporting certified byte-range requests, the Asset Canister will become much more capable. For example, byte range support can enable arbitrary seeking in HTML-based video and audio.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q3 2024",
            "status": "upcoming",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason",
            "imported": true
          },
          {
            "title": "Trait-Bound canister development using Candid",
            "overview": "A new way to synchronize Candid interface definitions with Rust source code that leverages the capabilities of macros and Rust's strong type system.",
            "description": "This feature introduces a new way to synchronize Candid interface definitions with Rust source code that leverages the capabilities of macros and Rust's strong type system.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "Q4 2024",
            "status": "upcoming",
            "is_community": false,
            "in_beta": false,
            "notes": "final",
            "imported": true
          },
          {
            "title": "Live canister metrics",
            "overview": "Expose key canister metrics in realtime that can be queried, such as cycle usage or memory consumption.",
            "description": "It is crucial that canisters be manageable and monitorable in an automated way, much like traditional Web2 services in cloud environments. This requires that key canister metrics be available through a canister API. A good starting point would be metrics such as a canister's cycles drain rate, memory consumption (heap and stable), or received calls per second. Such metrics are crucial for devs in order to ensure their dapps are running reliably and to take mitigating steps in case of issues.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason; community list (Jordan Last): https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/51 (monitoring part); related to canister lifecycle hooks"
          },
          {
            "title": "IC agents for additional languages",
            "overview": "Releasing IC agents for additional languages to broaden the support for languages that can interoperate with ICP.",
            "description": "IC agents that provide the functionality for a program to interact with the Internet Computer Protocol are available for a number of languages already. In order to facilitate further growth of ICP and new builders joining, it is planned to make IC agents available for a broader set of languages, in part also through a community effort.",
            "forum": "",
            "proposal": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "Implemented by both Dfinity and community"
          },
          {
            "title": "Mobile app IC agents",
            "overview": "IC agents for the Android and iOS mobile app platforms. Simplifies building native Android and iOS apps talking to canisters.",
            "description": "Currently, it is not straightforward to build a native mobile app for ICP as the Web-based IC agents need to be used, thus preventing a fully native implementation. This feature realizes IC agents for Android and iOS to simplify the development of native mobile ICP apps.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Specify placement subnet for new canisters",
            "overview": "When creating a new canister, the subnet on which it should be placed can be specified.",
            "description": "The subnet a canister is deployed to should be able to be specified at deploy time. It will be possible to specify a subnet explicitly or declare that a canister should be deployed next to some other canister by providing an ID.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason; community list"
          },
          {
            "title": "Verifiable canisters",
            "overview": "Tools for devs, such as TLA+, to verify the correctness of their canisters.",
            "description": "Having canisters verifiable is crucial for gaining trust by users. One important aspect of verifiability is the use of formal methods, e.g., using TLA+ models as done for many of the DFINITY-authored canisters, with the goal of enhancing assurance of correctness of canisters. This feature intends to bring such techniques from the internal use in DFINITY to the wider community and allow for a more broad-based adoption of those techniques in the community.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false
          },
          {
            "title": "dfx for macOS ARM arch",
            "overview": "The dfx toolchain is becoming native to the Mac's ARM-based architecture. This is necessary because the Rosetta 2 emulation layer is expected to be removed in the future.",
            "description": "The current dfx tooling for Apple Macintosh computers is still based on the x64 instruction set and requires the Rosetta 2 emulator to run on ARM-based Macs. This feature retrofits the dfx toolset to run also on ARM-based Macs natively without an emulator. This will improve performance and make dfx future proof as Rosetta 2 is temporary and will be removed at some point from macOS.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason"
          },
          {
            "title": "PocketIC shipped and bundled with dfx",
            "overview": "PocketIC, the new recommended standard tool for testing of dapps, is shipped and packaged with the dfx SDK.",
            "description": "Currently, the PocketIC is a standalone tool and shipped independently of ICP's dfx SDK. As a next step, it is integrated with dfx and shipped as a part of it. This integration of ICP's preferred dapp testing solution is another step in improving developer experience and reducing the burden for devs on ICP.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": ""
          },
          {
            "title": "Candid improvements",
            "overview": "This is a catch-all feature for improvements to Candid.",
            "description": "As part of this feature, Candid receives some improvements to further improve its utility.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": false,
            "in_beta": false,
            "notes": "?? details"
          },
          {
            "title": "Protocol Interface Specification evolution",
            "overview": "Improving version interoperability between different versions of the Internet Computer Protocol Specification.",
            "description": "Currently, new versions of the Internet Computer Potocol Specification are rolled out very homogeneously throughout all the subnets of ICP within a short time period following the release of the new version. With the advent of sovereign subnets like UTOPIA, version diversity of networks will grow and interoperability between different versions will be more challenging. <br><br> This feature enables subnets to make a certified claim about the protocol version they are running to other subnets. This information can be used to determine whether the subnet is compatible with the protocol version of another subnet that intends to communicate with it.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "response of Björn T: currently have problem that you don't know which version of spec is implemented when talking to IC; would like to, but don't have resources: subnet makes claim which IF spec version it implements; read from state tree; pull version of spec; mostly in dev process; need to adjust spec compliance tests; the more we go to UTOPIA, the more versions will diverge; need this as prerequisite; for UTOPIA would need better version compatibility, subnets will be on vastly different versions; feature becomes relevant; currently protocol not prepared, e.g., XNet changes only test version n to n-1 working together"
          },
          {
            "title": "Ingress deduplication",
            "overview": "Enhancing ingress deduplication to use a larger 24-hour deduplication window for ingress messages compared to the current 5-minute time window. Provides stronger guarantees, for example for financial applications.",
            "description": "Distributed systems like ICP face the problem that submitted messages may not get processed for various reasons, thus requiring them to be resubmitted. Deduplication is used to ensure resubmission does not lead to repeated processing, i.e., it ensures idempotency. The current deduplication mechanism of ingress messages submitted to a canister on ICP deduplicates messages only during a 5-minute time window. This is too small a time window for applications where value is at stake, e.g., financial applications. This feature improves the deduplication guarantees offered by ICP by realizing a much larger deduplication time window.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "IC-1335: https://dfinity.atlassian.net/browse/IC-1335"
          },
          {
            "title": "Easy asset creation",
            "overview": "Easy and streamlined creation of digital assets (both fungible and non-fungible) through out-of-the-box-deployable ledgers. For example, the creation of a new token through a proposal, without needing to manually deploy (and manage) the corresponding canisters.",
            "description": "Currently, the creation of a new digital asset on ICP is not straightforward and involves many steps, considerable technical knowledge, and ongoing maintainance efforts related to canister upgrades: Deploying a token means to deploy its token ledger and corresponding auxiliary canisters such as the index canister and maintaining those canisters in terms of software updates and cycles replenishment. This is technically rather involved and requires more technical skills than what should be the case for such a standard operation. This feature is about making the creation of a new digital asset on ICP as streamlined as reasonably possible. The idea is to allow for the creation of a new digital asset on ICP through just a proposal. A first target of this will be tokens following the ICRC-1/2/3 token standards, NFTs based on ICRC-7 and ICRC-37 could be a next step. Once implemented, anybody without deep technical knowledge about ICP's ledgers should be able to deploy a token on ICP, which is anticipated to be a great driver for new tokens on ICP.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "Out-of-the-box ledgers"
          },
          {
            "title": "Higher-level stable memory libraries",
            "overview": "The stable memory API is a great abstraction for orthogonal persistence on ICP; however, it is a low-level API and can be difficult to use.",
            "description": "Create more friendly, higher-level libraries that abstract away the complexity of working with the Stable Memory API.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "final; reviewed by Jason; community list"
          },
          {
            "title": "REST- &amp; JSON-centric interfaces",
            "overview": "REST and JSON-centric philosophy of interacting with ICP. Makes it easier for Web2 devs to onboard the ICP ecosystem.",
            "description": "This community request proposes to have stronger support for the REST paradigm and thus also JSON on the ICP, complementing (or even attempting to replace) the current Candid-driven experience. This would help make the developer experience more similar to what Web2 developers are used to and thus simplify dev onboarding on ICP.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list; merged requests by Jordan Last (https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/44) and Joseph Granata (https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/63)"
          },
          {
            "title": "Regulatory compliance support",
            "overview": "Making it easier to write regulatory compliant dapps.",
            "description": "This is a rather generic roadmap item about supporting canister devs in writing regulatory compliant code. One important aspect in this domain is to have a KYC solution available for dapps to use.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (D. Fisher); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/23"
          },
          {
            "title": "Automatic canister top-up using Web2 payment rails",
            "overview": "Allowing canisters to be topped up automatically via Web2 payment systems, e.g., credit card transfers.",
            "description": "Manually taking care of canister cycles balances is a tedious and error-prone process. Automating this process helps canister developers save time and avoid situations where their canisters run out of cycles and lead to a service degradation for their users. One approach for this is to automate canister top ups based on their current cycles balance and using traditional Web2 payment systems such as credit cards for cycles top ups.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "future",
            "is_community": true,
            "in_beta": false,
            "notes": "community list: https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/51"
          },
          {
            "title": "Bring Actix to the IC",
            "overview": "Bring Actix, one of the most powerful Web frameworks in Rust, to the IC. We should not be rebuilding this every time we do a dapp.",
            "description": "",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Joseph Granata); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/63"
          },
          {
            "title": "A file system on ICP",
            "overview": "A file system on ICP, to avoid building or emulating one whenever needed by a dapp.",
            "description": "Many projects need file-type capabilities. Instead of having each project re-build this functionality on their own, ICP should offer file system capabilities either as part of the system or as a user-space library that can be readily plugged into a dapp.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Joseph Granata); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/63"
          },
          {
            "title": "Easily upload files to ICP",
            "overview": "Upload files to the IC with a few lines of code.",
            "description": "Uploading files is a crucial functionality of many apps in Web2. Being able to easily, i.e., with a few lines of simple code, implement file upload functionality is crucial in order to make ICP competitive with existing Web2 technology stacks. One possible solution to allow for this is to provide a library for file upload that performs the \"heavy lifting\" and can be used with a few lines of code.",
            "status": "",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Joseph Granata); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/63"
          },
          {
            "title": "Motoko-written interactive Web UIs running in Wasm",
            "overview": "Implementing interactive Web UIs with Motoko, executing in the browser in Wasm. Analogous to .NET's Blazor.",
            "description": "Enable interactive Web UIs to be written in Motoko, compiled to Wasm, and executing efficiently in the browser is a next step towards providing a more streamlined developer experience in the Motoko ecosystem: Motoko can be used for both the backend and the frontend.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": true,
            "in_beta": false,
            "notes": "community list (Mike Adey); https://forum.dfinity.org/t/what-do-you-need-from-icp-in-2024/25726/16; building on JSInterop"
          },
          {
            "title": "Motoko editor support V2",
            "overview": "Improved Motoko support in VSCode, e.g., outline view, unused declaration warnings, organizing imports, Prettier 3 support, and AI-driven coding assistance.",
            "description": "This feature tackles improved support of Motoko in VSCode, some examples of which are given next: Outline view for Motoko files, jumping to the implementation of a symbol, warnings for unused declarations, organizing imports, Prettier 3.0 formatting, UX improvements for type checking large projects, better Mops and Vessel integration, improved wrapping rules for logical operators, and Motoko-optimized AI-driven coding assistance. This is instrumental in creating a more streamlined developer environment for Motoko and accelerate onboarding to the Motoko ecosystem.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc; debugging: on-line debugging; cannot use DFX etc.; PocketIC neither; support of AI like Copilot but specifically trained/optimized for Motoko, more specific, highlight, QA (relatively simple); testing: more easily handle unit tests, integration tests, run in IDE; coverage analysis (idea, not on roadmap)"
          },
          {
            "title": "Motoko package manager shipped with dfx",
            "overview": "Integrating the Mops package manager with dfx to improve DX.",
            "description": "Motoko currently has two package managers, Vessel, the original package manager for Motoko, and Mops, a fully on-chain package manager that is the recommended package manager for Motoko. This feature is about integrating the Mops Motoko package manager with dfx to further improve the developer experience.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc; ?? details; ?? Vessel still relevant?; Luc: Mops is recommended, but there are limitations: people do usually not like installing an extra package manager; why not ship it with Motoko; idea: integrate Mops with Motoko; not clear where it is coming, more an idea; another idea: use package manager in in playground; most people use Mops, more flexible, larger number of packages, more decentralized"
          },
          {
            "title": "More Motoko libraries",
            "overview": "Implementing, or funding the implementation of, additional Motoko libraries of frequently requested functionality.",
            "description": "A limitation of every young programming language like Motoko is that the selection of available open source libraries is substantially smaller than for mainstream languages. Therefore, determine commonly used smart contract functionality that should be offered as Motoko libraries. Invite the community to contribute to evolving the Motoko library ecosystem. At the same time, overhaul the existing Motoko base library for a more homogeneous design of common data structures and functionality that optimally fits the IC.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc; Luc: idea is to make new standard library designed with lessons learnt; selected data structures that work on IC; unified style -> Motoko standard library V2; fully reworked; use also high-quality community implementations"
          },
          {
            "title": "Language-interoperability support in Motoko",
            "overview": "Allowing the integration of libraries from other languages in Motoko (with some limitations).",
            "description": "Additionally boost the Motoko library ecosystem by supporting interoperability between Motoko and other languages that compile to Wasm. This would, e.g., allow the usage of Rust libraries in Motoko. The implementation road could start from an MVP with limited support (e.g. only stateless functions that do not save memory across calls, restricted types that can be passed across foreign-language calls) and continue towards potentially full-fledged interoperability enabled through the Wasm component model",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc; Luc: Rust libraries with constraints (e.g., stateless) can be integrated with Motoko; e.g., crypto libraries; full integration would be hard; in .Net you can use C++ with C# (interop); integrate high-performance code; other approaches: Wasm component model: multi-lang integration with own memory management per language/component (in Wasm WG); FFI: different type models, makes it more complicated, may not have direct mapping, may need to copy"
          },
          {
            "title": "Support of popular languages",
            "overview": "Supporting additional popular languages such as Dart, Java, C#, Go, or Swift, to implement canisters. Helping a broader range of devs to onboard ICP.",
            "description": "Having a broad selection of programming languages for programming smart contracts is beneficial for adoption as prospective programmers are then less likely to be required to learn a new language in order to onboard on ICP. As ICP's execution is based on WebAssembly (Wasm), any language that compiles to Wasm can in principal be used to implement canister smart contracts. However, without an available canister development kit, using a language is not straightforward. Thus, besides the already supported languages, Dart, Java, C#, Go, and Swift are example candidates for additional support through CDKs due to their widespread use.",
            "forum": "",
            "proposal": "",
            "wiki": "",
            "docs": "",
            "eta": "",
            "status": "",
            "is_community": false,
            "in_beta": false,
            "notes": "final; reviewed by Luc"
          }
        ]
      }
    ]
  }
]